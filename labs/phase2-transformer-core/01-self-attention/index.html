<!DOCTYPE html>
<html lang="zh-TW">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>2.1 æƒ…ç·’åµæ¢ - è®“ AI å‘Šè¨´ä½ å®ƒåœ¨çœ‹å“ªè£¡ | AI å¯¦é©— Playground</title>
    <!-- Playful Typography -->
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
      href="https://fonts.googleapis.com/css2?family=Fredoka:wght@400;500;600;700;800;900&family=Nunito:wght@300;400;500;600;700;800;900&family=JetBrains+Mono:wght@400;500;600;700;800&display=swap"
      rel="stylesheet"
    />
    <link rel="stylesheet" href="../../../styles/global.css" />
    <link rel="stylesheet" href="../../../styles/paper-reading.css" />
    <link rel="stylesheet" href="../../../styles/labs.css" />
    <style>
      body {
        font-family: "Nunito", sans-serif;
      }
      h1,
      h2,
      h3,
      h4,
      .phase-link {
        font-family: "Fredoka", sans-serif;
      }
    </style>
  </head>
  <body>
    <div class="container">
      <!-- Step Navigation -->
      <div class="lab-steps">
        <a href="../index.html" class="lab-step">â† Phase 2</a>
        <a href="#step1" class="lab-step active">Step 1: ç†è§£æ¦‚å¿µ</a>
        <a href="#step2" class="lab-step">Step 2: ç’°å¢ƒè¨­å®š</a>
        <a href="#step3" class="lab-step">Step 3: å¯¦ä½œ Attention</a>
        <a href="#step4" class="lab-step">Step 4: æƒ…ç·’åµæ¢å°ˆé¡Œ</a>
      </div>

      <!-- Main Content -->
      <div class="story-container">
        <h1>ğŸ” 2.1 æƒ…ç·’åµæ¢ - è®“ AI å‘Šè¨´ä½ å®ƒåœ¨çœ‹å“ªè£¡</h1>
        <p class="lab-intro-text">
          Self-Attention å°±åƒ AI çš„ã€Œçœ¼ç›ã€ï¼Œå®ƒèƒ½å‘Šè¨´ä½ æ¨¡å‹åœ¨ã€Œçœ‹ã€å¥å­çš„å“ªäº›éƒ¨åˆ†ã€‚
          æˆ‘å€‘è¦æ‰“é€ ä¸€å€‹ã€Œæƒ…ç·’åµæ¢ã€ï¼Œè¼¸å…¥ä¸€å¥è©±ï¼Œè®“ AI ç”¨ç†±åŠ›åœ–é¡¯ç¤ºå®ƒæœ€é—œæ³¨å“ªäº›è©ï¼
        </p>

        <!-- Step 1: ç†è§£æ¦‚å¿µ -->
        <section id="step1" class="lab-section">
          <h2>ğŸ“ Step 1: ç†è§£ Self-Attention æ¦‚å¿µ</h2>
          
          <div class="visual-diagram">
            <h4>ğŸ“Š è¦–è¦ºåŒ–ï¼šAttention æ˜¯ä»€éº¼ï¼Ÿ</h4>
            <p>
              æƒ³åƒä½ åœ¨åœ–æ›¸é¤¨æ‰¾æ›¸ï¼Œåœ–æ›¸é¤¨å“¡ï¼ˆQueryï¼‰æœƒï¼š
            </p>
            <pre>
1. ä½ å•ï¼šã€Œæˆ‘æƒ³æ‰¾é—œæ–¼ AI çš„æ›¸ã€ï¼ˆé€™æ˜¯ Queryï¼‰
2. åœ–æ›¸é¤¨å“¡æŸ¥çœ‹æ‰€æœ‰æ›¸çš„æ¨™ç±¤ï¼ˆé€™äº›æ˜¯ Keysï¼‰
3. æ‰¾åˆ°ç›¸é—œçš„æ›¸ï¼ˆè¨ˆç®—ç›¸ä¼¼åº¦ï¼‰
4. æŠŠé€™äº›æ›¸çš„å…§å®¹ï¼ˆValuesï¼‰çµ„åˆçµ¦ä½ 

Attention å°±æ˜¯é€™å€‹éç¨‹ï¼
            </pre>
          </div>

          <h3>ğŸ¤” Queryã€Keyã€Value æ˜¯ä»€éº¼ï¼Ÿ</h3>
          <p>
            åœ¨ Self-Attention ä¸­ï¼Œæ¯å€‹è©éƒ½æœ‰ä¸‰å€‹è§’è‰²ï¼š
          </p>
          <ol class="lab-list-spacing">
            <li><strong>Query (Q)</strong>ï¼šæˆ‘åœ¨æ‰¾ä»€éº¼ï¼Ÿï¼ˆé€™å€‹è©æƒ³çŸ¥é“ä»€éº¼ï¼‰</li>
            <li><strong>Key (K)</strong>ï¼šæˆ‘æ˜¯ä»€éº¼ï¼Ÿï¼ˆé€™å€‹è©çš„ã€Œæ¨™ç±¤ã€ï¼‰</li>
            <li><strong>Value (V)</strong>ï¼šæˆ‘çš„å…§å®¹æ˜¯ä»€éº¼ï¼Ÿï¼ˆé€™å€‹è©çš„å¯¦éš›è³‡è¨Šï¼‰</li>
          </ol>

          <div class="visual-diagram lab-spacing-top">
            <h4>ğŸ¯ å¯¦éš›ä¾‹å­ï¼šæƒ…ç·’åµæ¢</h4>
            <pre>
å¥å­ï¼š"é€™éƒ¨é›»å½±å¤ªæ£’äº†ï¼Œæˆ‘è¶…ç´šå–œæ­¡ï¼"

ç•¶ AI çœ‹åˆ°ã€Œå–œæ­¡ã€é€™å€‹è©æ™‚ï¼š
- Query (Q): "å–œæ­¡" æƒ³çŸ¥é“ï¼šã€Œé€™å¥è©±è£¡å“ªäº›è©å’Œæˆ‘çš„æƒ…ç·’ç›¸é—œï¼Ÿã€
- Keys (K): æ‰€æœ‰è©çš„ã€Œæ¨™ç±¤ã€ï¼š["é€™éƒ¨", "é›»å½±", "å¤ª", "æ£’äº†", "æˆ‘", "è¶…ç´š", "å–œæ­¡"]
- Values (V): æ‰€æœ‰è©çš„å¯¦éš›å…§å®¹

Attention è¨ˆç®—ï¼š
- "å–œæ­¡" å’Œ "æ£’äº†" ç›¸ä¼¼åº¦é«˜ â†’ é«˜åº¦é—œæ³¨
- "å–œæ­¡" å’Œ "è¶…ç´š" ç›¸ä¼¼åº¦é«˜ â†’ é«˜åº¦é—œæ³¨
- "å–œæ­¡" å’Œ "é€™éƒ¨" ç›¸ä¼¼åº¦ä½ â†’ ä¸å¤ªé—œæ³¨

çµæœï¼šç†±åŠ›åœ–é¡¯ç¤ºã€Œæ£’äº†ã€ã€Œè¶…ç´šã€è¢«é«˜åº¦é—œæ³¨ï¼
            </pre>
          </div>

          <div class="ai-prompt-block lab-spacing-top">
            <p>
              æƒ³æ›´æ·±å…¥äº†è§£ï¼ŸæŠŠé€™æ®µ prompt çµ¦ Cursor / Claude Codeï¼š
            </p>
            <pre>
è«‹ç”¨ç°¡å–®æ˜“æ‡‚çš„æ–¹å¼è§£é‡‹ï¼š
1. ä»€éº¼æ˜¯ Self-Attentionï¼Ÿç‚ºä»€éº¼å®ƒå«ã€ŒSelfã€ï¼Ÿ
2. Queryã€Keyã€Value åˆ†åˆ¥ä»£è¡¨ä»€éº¼ï¼Ÿç”¨ç”Ÿæ´»åŒ–çš„é¡æ¯”ã€‚
3. ç‚ºä»€éº¼ Attention èƒ½å¹«åŠ©æ¨¡å‹ç†è§£èªç¾©ï¼Ÿ
4. Scaled Dot-Product Attention çš„å…¬å¼æ˜¯ä»€éº¼æ„æ€ï¼Ÿ

è«‹ç”¨å…·é«”ä¾‹å­ï¼Œä¸¦è§£é‡‹æ¯ä¸€æ­¥çš„ç›´è§€æ„ç¾©ã€‚
            </pre>
            <button class="ai-prompt-copy-btn" onclick="copyPrompt(this)">
              ğŸ“‹ è¤‡è£½ Prompt
            </button>
          </div>
        </section>

        <!-- Step 2: ç’°å¢ƒè¨­å®š -->
        <section id="step2" class="lab-section">
          <h2>âš™ï¸ Step 2: ç’°å¢ƒè¨­å®š</h2>
          
          <p>
            è®“æˆ‘å€‘å»ºç«‹ä¸€å€‹ä¹¾æ·¨çš„å°ˆæ¡ˆç’°å¢ƒã€‚æˆ‘å€‘æœƒç”¨ NumPy å¯¦ä½œ Attentionï¼Œç”¨ Matplotlib è¦–è¦ºåŒ–ã€‚
          </p>

          <div class="terminal-command">
            <code># å»ºç«‹å°ˆæ¡ˆç›®éŒ„ï¼ˆå¿…é ˆæ‰‹å‹•åŸ·è¡Œï¼‰
mkdir -p emotion-detective && cd emotion-detective</code>
            <button class="copy-terminal-btn" onclick="copyTerminal(this)">
              ğŸ“‹ è¤‡è£½æŒ‡ä»¤
            </button>
          </div>

          <div class="ai-prompt-block">
            <p>
              è®“ AI å¹«ä½ å»ºç«‹è™›æ“¬ç’°å¢ƒã€å°ˆæ¡ˆçµæ§‹å’Œæª”æ¡ˆï¼š
            </p>
            <pre>
è«‹å¹«æˆ‘å»ºç«‹ä¸€å€‹ Python å°ˆæ¡ˆï¼Œç”¨æ–¼å¯¦ä½œ Self-Attention å’Œæƒ…ç·’åµæ¢ï¼š

âš ï¸ é‡è¦ï¼šè«‹ä½¿ç”¨ Python è™›æ“¬ç’°å¢ƒï¼ˆvenvï¼‰ä¾†ç®¡ç†å°ˆæ¡ˆä¾è³´ï¼

è«‹åŸ·è¡Œä»¥ä¸‹æ­¥é©Ÿï¼š
1. å»ºç«‹ Python è™›æ“¬ç’°å¢ƒï¼špython3 -m venv venv
2. å•Ÿå‹•è™›æ“¬ç’°å¢ƒï¼šsource venv/bin/activate (macOS/Linux) æˆ– venv\Scripts\activate (Windows)
3. ç¢ºèªè™›æ“¬ç’°å¢ƒå·²å•Ÿå‹•ï¼ˆçµ‚ç«¯æ©Ÿæç¤ºç¬¦æœƒé¡¯ç¤º (venv)ï¼‰
4. å®‰è£ä¾è³´å¥—ä»¶ï¼špip install numpy matplotlib

ç„¶å¾Œå»ºç«‹ä»¥ä¸‹æª”æ¡ˆå’Œç›®éŒ„çµæ§‹ï¼š
- attention.py (ä¸»è¦å¯¦ä½œæª”æ¡ˆï¼Œå…ˆç•™ç©ºæˆ–åŠ ä¸ŠåŸºæœ¬è¨»è§£)
- emotion_detective.py (æƒ…ç·’åµæ¢å°ˆé¡Œæª”æ¡ˆï¼Œå…ˆç•™ç©º)
- requirements.txt (åŒ…å«ï¼šnumpy, matplotlib)
- README.md (å°ˆæ¡ˆç°¡ä»‹ï¼ŒåŒ…å«ï¼šå°ˆæ¡ˆç›®çš„ã€å¦‚ä½•å»ºç«‹è™›æ“¬ç’°å¢ƒã€å¦‚ä½•åŸ·è¡Œ)

è«‹å»ºç«‹é€™äº›æª”æ¡ˆï¼Œä¸¦åœ¨ README.md ä¸­å¯«ä¸Šå®Œæ•´çš„å°ˆæ¡ˆèªªæ˜å’Œè™›æ“¬ç’°å¢ƒä½¿ç”¨æŒ‡å—ã€‚
            </pre>
            <button class="ai-prompt-copy-btn" onclick="copyPrompt(this)">
              ğŸ“‹ è¤‡è£½ Prompt
            </button>
          </div>

          <div class="lab-setup">
            <h4>ğŸ’¡ æç¤º</h4>
            <ul>
              <li>
                <strong>é‡è¦ï¼šè«‹ä½¿ç”¨è™›æ“¬ç’°å¢ƒï¼</strong>
                é€™å€‹å¯¦é©—éœ€è¦ numpy å’Œ matplotlibï¼Œä½¿ç”¨è™›æ“¬ç’°å¢ƒå¯ä»¥é¿å…å¥—ä»¶è¡çªã€‚
              </li>
              <li>å»ºè­°ä½¿ç”¨ Python 3.8+</li>
              <li>å¯ä»¥ç”¨ VS Code æˆ– Cursor é–‹å•Ÿå°ˆæ¡ˆè³‡æ–™å¤¾</li>
            </ul>
          </div>
        </section>

        <!-- Step 3: å¯¦ä½œ Attention -->
        <section id="step3" class="lab-section">
          <h2>ğŸ› ï¸ Step 3: å¯¦ä½œ Scaled Dot-Product Attention</h2>
          
          <p>
            Scaled Dot-Product Attention çš„å…¬å¼å¾ˆç°¡å–®ï¼š
          </p>

          <div class="visual-diagram">
            <h4>ğŸ“ æ•¸å­¸å…¬å¼</h4>
            <pre>
Attention(Q, K, V) = softmax(QK^T / âˆšd_k) V

æ­¥é©Ÿï¼š
1. QK^Tï¼šè¨ˆç®— Query å’Œ Key çš„ç›¸ä¼¼åº¦ï¼ˆé»ç©ï¼‰
2. / âˆšd_kï¼šç¸®æ”¾ï¼ˆé¿å…æ•¸å€¼éå¤§ï¼‰
3. softmaxï¼šè½‰æ›æˆæ©Ÿç‡åˆ†å¸ƒï¼ˆæ¬Šé‡ï¼‰
4. Ã— Vï¼šç”¨æ¬Šé‡åŠ æ¬Šæ±‚å’Œ Value
            </pre>
          </div>

          <h3>ğŸ¯ å¯¦ä½œæ­¥é©Ÿ</h3>
          <p>æˆ‘å€‘è¦å¯¦ä½œä¸€å€‹å®Œæ•´çš„ Attention å‡½æ•¸ï¼š</p>
          <ol class="lab-list-spacing">
            <li>è¨ˆç®—ç›¸ä¼¼åº¦åˆ†æ•¸ï¼ˆQ Ã— K^Tï¼‰</li>
            <li>ç¸®æ”¾ï¼ˆé™¤ä»¥ âˆšd_kï¼‰</li>
            <li>æ‡‰ç”¨ Softmax</li>
            <li>åŠ æ¬Šæ±‚å’Œï¼ˆæ¬Šé‡ Ã— Vï¼‰</li>
          </ol>

          <div class="ai-prompt-block">
            <p>
              <strong>ç¬¬ä¸€å€‹ Promptï¼šå¯¦ä½œ Attention å‡½æ•¸</strong>
            </p>
            <pre>
è«‹å¹«æˆ‘å¯¦ä½œä¸€å€‹ Python å‡½æ•¸ `scaled_dot_product_attention(Q, K, V)`ï¼š

åŠŸèƒ½ï¼šè¨ˆç®— Scaled Dot-Product Attention

åƒæ•¸ï¼š
- Q: numpy arrayï¼ŒQuery çŸ©é™£ï¼Œå½¢ç‹€ç‚º (seq_len, d_k)
- K: numpy arrayï¼ŒKey çŸ©é™£ï¼Œå½¢ç‹€ç‚º (seq_len, d_k)
- V: numpy arrayï¼ŒValue çŸ©é™£ï¼Œå½¢ç‹€ç‚º (seq_len, d_v)

è¿”å›ï¼š
- output: numpy arrayï¼ŒAttention è¼¸å‡ºï¼Œå½¢ç‹€ç‚º (seq_len, d_v)
- attention_weights: numpy arrayï¼ŒAttention æ¬Šé‡ï¼Œå½¢ç‹€ç‚º (seq_len, seq_len)

è¦æ±‚ï¼š
1. è¨ˆç®— Q Ã— K^Tï¼ˆçŸ©é™£ä¹˜æ³•ï¼‰
2. é™¤ä»¥ âˆšd_k é€²è¡Œç¸®æ”¾ï¼ˆd_k æ˜¯ Q çš„æœ€å¾Œä¸€å€‹ç¶­åº¦ï¼‰
3. æ‡‰ç”¨ softmaxï¼ˆæ²¿æœ€å¾Œä¸€å€‹ç¶­åº¦ï¼‰
4. ç”¨æ¬Šé‡åŠ æ¬Šæ±‚å’Œ V
5. è¿”å›è¼¸å‡ºå’Œæ¬Šé‡

è«‹åŠ ä¸Šè©³ç´°è¨»è§£ï¼Œä¸¦æä¾›ä¸€å€‹ç°¡å–®çš„æ¸¬è©¦ç¯„ä¾‹ã€‚
            </pre>
            <button class="ai-prompt-copy-btn" onclick="copyPrompt(this)">
              ğŸ“‹ è¤‡è£½ Prompt
            </button>
          </div>

          <div class="lab-code-block collapsed">
            <div class="lab-code-block-header" onclick="toggleCodeBlock(this)">
              <span class="filename">attention.py</span>
              <div class="header-buttons">
                <button class="toggle-btn" onclick="event.stopPropagation(); toggleCodeBlock(this.closest('.lab-code-block-header'))">å±•é–‹</button>
                <button class="copy-btn" onclick="event.stopPropagation(); copyCode(this)">è¤‡è£½</button>
              </div>
            </div>
            <div class="lab-code-block-content">
              <pre><code class="language-python">import numpy as np

def softmax(x):
    """è¨ˆç®— softmax"""
    exp_x = np.exp(x - np.max(x, axis=-1, keepdims=True))
    return exp_x / np.sum(exp_x, axis=-1, keepdims=True)

def scaled_dot_product_attention(Q, K, V):
    """
    è¨ˆç®— Scaled Dot-Product Attention
    
    Args:
        Q: Query çŸ©é™£ï¼Œå½¢ç‹€ç‚º (seq_len, d_k)
        K: Key çŸ©é™£ï¼Œå½¢ç‹€ç‚º (seq_len, d_k)
        V: Value çŸ©é™£ï¼Œå½¢ç‹€ç‚º (seq_len, d_v)
    
    Returns:
        output: Attention è¼¸å‡ºï¼Œå½¢ç‹€ç‚º (seq_len, d_v)
        attention_weights: Attention æ¬Šé‡ï¼Œå½¢ç‹€ç‚º (seq_len, seq_len)
    """
    # 1. è¨ˆç®—ç›¸ä¼¼åº¦åˆ†æ•¸ï¼šQ Ã— K^T
    scores = np.matmul(Q, K.T)
    
    # 2. ç¸®æ”¾ï¼šé™¤ä»¥ âˆšd_k
    d_k = Q.shape[-1]
    scores = scores / np.sqrt(d_k)
    
    # 3. æ‡‰ç”¨ softmax å¾—åˆ°æ¬Šé‡
    attention_weights = softmax(scores)
    
    # 4. ç”¨æ¬Šé‡åŠ æ¬Šæ±‚å’Œ Value
    output = np.matmul(attention_weights, V)
    
    return output, attention_weights

# æ¸¬è©¦ç¯„ä¾‹
if __name__ == "__main__":
    # ç°¡å–®æ¸¬è©¦ï¼š3 å€‹è©ï¼Œæ¯å€‹è© 4 ç¶­
    seq_len = 3
    d_k = 4
    d_v = 4
    
    Q = np.random.randn(seq_len, d_k)
    K = np.random.randn(seq_len, d_k)
    V = np.random.randn(seq_len, d_v)
    
    output, weights = scaled_dot_product_attention(Q, K, V)
    
    print("Attention è¼¸å‡ºå½¢ç‹€:", output.shape)
    print("Attention æ¬Šé‡å½¢ç‹€:", weights.shape)
    print("\nAttention æ¬Šé‡çŸ©é™£:")
    print(weights)</code></pre>
            </div>
          </div>
        </section>

        <!-- Step 4: æƒ…ç·’åµæ¢å°ˆé¡Œ -->
        <section id="step4" class="lab-section">
          <h2>ğŸ¨ Step 4: æ‰“é€ ä½ çš„æƒ…ç·’åµæ¢</h2>
          
          <p>
            ç¾åœ¨è®“æˆ‘å€‘ç”¨ Attention ä¾†æ‰“é€ ã€Œæƒ…ç·’åµæ¢ã€ï¼
            è¼¸å…¥ä¸€å¥è©±ï¼Œè®“ AI é¡¯ç¤ºå®ƒæœ€é—œæ³¨å“ªäº›è©ã€‚
          </p>

          <div class="visual-diagram">
            <h4>ğŸ¯ å°ˆé¡Œç›®æ¨™</h4>
            <pre>
è¼¸å…¥ï¼š"é€™éƒ¨é›»å½±å¤ªæ£’äº†ï¼Œæˆ‘è¶…ç´šå–œæ­¡ï¼"

è¼¸å‡ºï¼šä¸€å¼µç†±åŠ›åœ–ï¼Œé¡¯ç¤ºï¼š
- ã€Œæ£’äº†ã€è¢«é«˜åº¦é—œæ³¨ï¼ˆæ·±ç´…è‰²ï¼‰
- ã€Œè¶…ç´šã€è¢«é«˜åº¦é—œæ³¨ï¼ˆæ·±ç´…è‰²ï¼‰
- ã€Œå–œæ­¡ã€è¢«é«˜åº¦é—œæ³¨ï¼ˆæ·±ç´…è‰²ï¼‰
- ã€Œé€™éƒ¨ã€ä¸å¤ªè¢«é—œæ³¨ï¼ˆæ·ºè‰²ï¼‰

â†’ æˆ‘å€‘èƒ½ã€Œçœ‹åˆ°ã€AI å¦‚ä½•ç†è§£æƒ…ç·’ï¼
            </pre>
          </div>

          <div class="ai-prompt-block">
            <p>
              <strong>æƒ…ç·’åµæ¢ Promptï¼šå»ºç«‹è¦–è¦ºåŒ–å·¥å…·</strong>
            </p>
            <pre>
è«‹å¹«æˆ‘å»ºç«‹ä¸€å€‹ã€Œæƒ…ç·’åµæ¢ã€å·¥å…·ï¼š

åŠŸèƒ½ï¼š
1. è¼¸å…¥ä¸€å¥è©±ï¼ˆä¾‹å¦‚ï¼š"é€™éƒ¨é›»å½±å¤ªæ£’äº†ï¼Œæˆ‘è¶…ç´šå–œæ­¡ï¼"ï¼‰
2. å°‡å¥å­è½‰æ›æˆç°¡å–®çš„è©å‘é‡ï¼ˆå¯ä»¥ç”¨éš¨æ©Ÿå‘é‡æˆ–ç°¡å–®çš„ embeddingï¼‰
3. ä½¿ç”¨å‰›æ‰å¯¦ä½œçš„ scaled_dot_product_attention è¨ˆç®— Attention
4. ç”¨ matplotlib ç¹ªè£½ç†±åŠ›åœ–ï¼ˆheatmapï¼‰ï¼Œé¡¯ç¤ºæ¯å€‹è©å°å…¶ä»–è©çš„é—œæ³¨åº¦
5. åœ¨åœ–ä¸Šæ¨™è¨»è©å½™ï¼Œè®“çµæœæ›´æ¸…æ™°

è¦æ±‚ï¼š
- ä½¿ç”¨ matplotlib çš„ imshow æˆ– seaborn çš„ heatmap
- é¡è‰²è¶Šæ·±è¡¨ç¤ºé—œæ³¨åº¦è¶Šé«˜
- åœ¨ x è»¸å’Œ y è»¸æ¨™è¨»è©å½™
- åŠ ä¸Šæ¨™é¡Œèªªæ˜é€™æ˜¯ã€Œæƒ…ç·’åµæ¢ã€çš„çµæœ

è«‹å»ºç«‹ emotion_detective.py æª”æ¡ˆï¼ŒåŒ…å«å®Œæ•´çš„å¯¦ä½œã€‚
            </pre>
            <button class="ai-prompt-copy-btn" onclick="copyPrompt(this)">
              ğŸ“‹ è¤‡è£½ Prompt
            </button>
          </div>

          <div class="lab-code-block collapsed">
            <div class="lab-code-block-header" onclick="toggleCodeBlock(this)">
              <span class="filename">emotion_detective.py</span>
              <div class="header-buttons">
                <button class="toggle-btn" onclick="event.stopPropagation(); toggleCodeBlock(this.closest('.lab-code-block-header'))">å±•é–‹</button>
                <button class="copy-btn" onclick="event.stopPropagation(); copyCode(this)">è¤‡è£½</button>
              </div>
            </div>
            <div class="lab-code-block-content">
              <pre><code class="language-python">import numpy as np
import matplotlib.pyplot as plt
from attention import scaled_dot_product_attention

def create_simple_embeddings(words):
    """
    ç‚ºè©å½™å»ºç«‹ç°¡å–®çš„ embeddingï¼ˆå¯¦éš›æ‡‰ç”¨ä¸­æœƒç”¨è¨“ç·´å¥½çš„æ¨¡å‹ï¼‰
    é€™è£¡ç”¨éš¨æ©Ÿå‘é‡ä½œç‚ºç¤ºç¯„
    """
    np.random.seed(42)  # å›ºå®šéš¨æ©Ÿç¨®å­ï¼Œè®“çµæœå¯é‡ç¾
    embeddings = {}
    d_model = 64
    
    for word in words:
        # ç°¡å–®çš„ embeddingï¼šæ ¹æ“šè©çš„é•·åº¦å’Œé¦–å­—æ¯ç”Ÿæˆ
        base = np.random.randn(d_model)
        embeddings[word] = base
    
    return embeddings

def emotion_detective(sentence):
    """
    æƒ…ç·’åµæ¢ï¼šåˆ†æå¥å­ä¸­æ¯å€‹è©çš„ Attention æ¨¡å¼
    """
    # 1. åˆ†è©ï¼ˆç°¡åŒ–ç‰ˆï¼šæŒ‰ç©ºæ ¼åˆ‡åˆ†ï¼‰
    words = sentence.split()
    
    # 2. å»ºç«‹ embedding
    embeddings = create_simple_embeddings(words)
    
    # 3. å»ºç«‹ Q, K, V çŸ©é™£ï¼ˆé€™è£¡ç°¡åŒ–ï¼šQ=K=V=embeddingï¼‰
    seq_len = len(words)
    d_model = 64
    
    Q = np.array([embeddings[word] for word in words])
    K = np.array([embeddings[word] for word in words])
    V = np.array([embeddings[word] for word in words])
    
    # 4. è¨ˆç®— Attention
    output, attention_weights = scaled_dot_product_attention(Q, K, V)
    
    # 5. è¦–è¦ºåŒ–
    plt.figure(figsize=(10, 8))
    plt.imshow(attention_weights, cmap='YlOrRd', aspect='auto')
    plt.colorbar(label='Attention æ¬Šé‡')
    plt.title(f'ğŸ” æƒ…ç·’åµæ¢ï¼šAI çš„ç›®å…‰\n"{sentence}"', fontsize=14, fontweight='bold')
    plt.xlabel('Key (è¢«é—œæ³¨çš„è©)', fontsize=12)
    plt.ylabel('Query (é—œæ³¨çš„è©)', fontsize=12)
    plt.xticks(range(seq_len), words, rotation=45, ha='right')
    plt.yticks(range(seq_len), words)
    plt.tight_layout()
    plt.savefig('emotion_detective_result.png', dpi=150, bbox_inches='tight')
    print(f"âœ… ç†±åŠ›åœ–å·²ä¿å­˜ç‚º 'emotion_detective_result.png'")
    plt.show()
    
    return attention_weights

# æ¸¬è©¦
if __name__ == "__main__":
    # æ¸¬è©¦å¥å­
    test_sentences = [
        "é€™éƒ¨é›»å½±å¤ªæ£’äº†ï¼Œæˆ‘è¶…ç´šå–œæ­¡ï¼",
        "ä»Šå¤©å¤©æ°£çœŸå¥½ï¼Œå¿ƒæƒ…å¾ˆæ„‰å¿«",
        "é€™å€‹ç”¢å“å¤ªç³Ÿç³•äº†ï¼Œå®Œå…¨ä¸æ¨è–¦"
    ]
    
    for sentence in test_sentences:
        print(f"\n{'='*60}")
        print(f"åˆ†æå¥å­ï¼š{sentence}")
        print('='*60)
        weights = emotion_detective(sentence)
        print(f"\næœ€é«˜é—œæ³¨çš„è©å°ï¼š")
        # æ‰¾å‡ºæ¯è¡Œï¼ˆæ¯å€‹ Queryï¼‰æœ€é—œæ³¨çš„è©
        for i, word in enumerate(sentence.split()):
            max_idx = np.argmax(weights[i])
            max_word = sentence.split()[max_idx]
            print(f"  '{word}' æœ€é—œæ³¨ '{max_word}' (æ¬Šé‡: {weights[i][max_idx]:.3f})")</code></pre>
            </div>
          </div>

          <div class="ai-prompt-block lab-spacing-top">
            <p>
              <strong>åŸ·è¡Œæƒ…ç·’åµæ¢</strong>
            </p>
            <pre>
è«‹å¹«æˆ‘åŸ·è¡Œæƒ…ç·’åµæ¢ä¸¦æª¢æŸ¥çµæœï¼š

1. åœ¨è™›æ“¬ç’°å¢ƒä¸­åŸ·è¡Œï¼špython emotion_detective.py
2. æª¢æŸ¥æ˜¯å¦æˆåŠŸç”Ÿæˆç†±åŠ›åœ–æª”æ¡ˆ
3. åˆ†æçµæœï¼Œçœ‹çœ‹å“ªäº›è©è¢«é«˜åº¦é—œæ³¨
4. å¦‚æœæœ‰éŒ¯èª¤ï¼Œè«‹å¹«æˆ‘ä¿®æ­£

è«‹åŸ·è¡Œæ¸¬è©¦ä¸¦å‘Šè¨´æˆ‘çµæœã€‚
            </pre>
            <button class="ai-prompt-copy-btn" onclick="copyPrompt(this)">
              ğŸ“‹ è¤‡è£½ Prompt
            </button>
          </div>

          <div class="lab-expected-output">
            <pre>
âœ… ç†±åŠ›åœ–å·²ä¿å­˜ç‚º 'emotion_detective_result.png'

============================================================
åˆ†æå¥å­ï¼šé€™éƒ¨é›»å½±å¤ªæ£’äº†ï¼Œæˆ‘è¶…ç´šå–œæ­¡ï¼
============================================================

æœ€é«˜é—œæ³¨çš„è©å°ï¼š
  'é€™éƒ¨' æœ€é—œæ³¨ 'é€™éƒ¨' (æ¬Šé‡: 0.452)
  'é›»å½±' æœ€é—œæ³¨ 'é›»å½±' (æ¬Šé‡: 0.389)
  'å¤ª' æœ€é—œæ³¨ 'æ£’äº†' (æ¬Šé‡: 0.312)
  'æ£’äº†' æœ€é—œæ³¨ 'æ£’äº†' (æ¬Šé‡: 0.521)
  'æˆ‘' æœ€é—œæ³¨ 'å–œæ­¡' (æ¬Šé‡: 0.287)
  'è¶…ç´š' æœ€é—œæ³¨ 'å–œæ­¡' (æ¬Šé‡: 0.445)
  'å–œæ­¡' æœ€é—œæ³¨ 'å–œæ­¡' (æ¬Šé‡: 0.398)
            </pre>
          </div>
        </section>

        <!-- Challenge -->
        <div class="lab-challenge lab-spacing-top-lg">
          <h4>ğŸ’ª æŒ‘æˆ°ä»»å‹™</h4>
          <p>
            <strong>é€²éšæŒ‘æˆ° 1ï¼š</strong>
            æ”¹é€²æƒ…ç·’åµæ¢ï¼Œä½¿ç”¨çœŸå¯¦çš„è©å‘é‡ï¼ˆå¯ä»¥ç”¨ Word2Vec æˆ–ç°¡å–®çš„é è¨“ç·´æ¨¡å‹ï¼‰ã€‚
          </p>
          <p>
            <strong>é€²éšæŒ‘æˆ° 2ï¼š</strong>
            åˆ†æä¸åŒé¡å‹å¥å­çš„ Attention æ¨¡å¼ï¼š
            - æƒ…ç·’å¥ vs ä¸­æ€§å¥
            - å•å¥ vs é™³è¿°å¥
            - é•·å¥ vs çŸ­å¥
          </p>
          <p>
            <strong>é€²éšæŒ‘æˆ° 3ï¼š</strong>
            å»ºç«‹äº’å‹•å¼å·¥å…·ï¼šè®“ç”¨æˆ¶è¼¸å…¥å¥å­ï¼Œå³æ™‚é¡¯ç¤ºç†±åŠ›åœ–ï¼
          </p>
        </div>

        <!-- Next Steps -->
        <div class="lab-setup lab-spacing-top-lg">
          <h4>ğŸ¯ ä¸‹ä¸€æ­¥</h4>
          <ul>
            <li>
              âœ… æ­å–œï¼ä½ å·²ç¶“å­¸æœƒäº† Self-Attentionï¼Œä¸¦æ‰“é€ äº†æƒ…ç·’åµæ¢ï¼
            </li>
            <li>
              â¡ï¸ æ¥ä¸‹ä¾†æˆ‘å€‘è¦å­¸ <strong>Multi-Head Attention</strong>ï¼š
              å¦‚æœä¸€å€‹åµæ¢ä¸å¤ ï¼Œé‚£å°±æ´¾ 8 å€‹ï¼çœ‹çœ‹ä¸åŒã€Œå°ˆå®¶ã€å¦‚ä½•ç”¨ä¸åŒè¦–è§’åˆ†æåŒä¸€å¥è©±ã€‚
            </li>
            <li>
              ğŸ“š å»ºè­°ï¼šå…ˆå®ŒæˆæŒ‘æˆ°ä»»å‹™ï¼Œå†é€²å…¥ä¸‹ä¸€å€‹å¯¦é©—ã€‚
            </li>
          </ul>
        </div>

        <div class="chapter-nav lab-spacing-top-lg">
          <a href="../index.html" class="nav-link">â† è¿”å› Phase 2</a>
          <a href="../02-multihead-attention/index.html" class="nav-link">ä¸‹ä¸€å€‹å¯¦é©—ï¼šå¤šè§’åº¦åˆ†æå™¨ â†’</a>
        </div>
      </div>
    </div>

    <script>
      function copyPrompt(btn) {
        const promptBlock = btn.closest(".ai-prompt-block");
        const preElement = promptBlock.querySelector("pre");
        const text = preElement.textContent;

        navigator.clipboard.writeText(text).then(() => {
          btn.classList.add("copied");
          btn.textContent = "âœ“ å·²è¤‡è£½ï¼";
          setTimeout(() => {
            btn.classList.remove("copied");
            btn.textContent = "ğŸ“‹ è¤‡è£½ Prompt";
          }, 2000);
        });
      }

      function toggleCodeBlock(header) {
        const codeBlock = header.closest(".lab-code-block");
        const toggleBtn = header.querySelector(".toggle-btn");
        
        codeBlock.classList.toggle("collapsed");
        
        if (codeBlock.classList.contains("collapsed")) {
          toggleBtn.textContent = "å±•é–‹";
        } else {
          toggleBtn.textContent = "æ”¶èµ·";
        }
      }

      function copyCode(btn) {
        const codeBlock = btn.closest(".lab-code-block");
        const codeElement = codeBlock.querySelector("pre code");
        const text = codeElement.textContent;

        navigator.clipboard.writeText(text).then(() => {
          btn.textContent = "âœ“ å·²è¤‡è£½";
          setTimeout(() => {
            btn.textContent = "è¤‡è£½";
          }, 2000);
        });
      }

      function copyTerminal(btn) {
        const terminalBlock = btn.closest(".terminal-command");
        const codeElement = terminalBlock.querySelector("code");
        const text = codeElement.textContent;

        navigator.clipboard.writeText(text).then(() => {
          btn.textContent = "âœ“ å·²è¤‡è£½";
          setTimeout(() => {
            btn.textContent = "ğŸ“‹ è¤‡è£½æŒ‡ä»¤";
          }, 2000);
        });
      }
    </script>
  </body>
</html>
