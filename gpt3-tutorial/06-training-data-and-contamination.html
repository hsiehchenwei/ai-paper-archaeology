<!DOCTYPE html>
<html lang="zh-TW">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>補充內容:訓練資料與資料污染 - GPT-3 論文深度解析</title>
    <link rel="stylesheet" href="../styles/global.css">
    <link rel="stylesheet" href="../styles/paper-reading.css">
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
    <div class="container">
        <div class="header-section">
            <h1>📊 補充:訓練資料集與資料污染</h1>
            <div class="paper-meta">
                <div class="meta-item">
                    <strong>論文章節</strong>
                    Section 2.2 (Training Dataset) + Section 4 (Data Contamination)
                </div>
                <div class="meta-item">
                    <strong>重要性</strong>
                    ⭐⭐⭐ 非常重要但原教學缺漏
                </div>
            </div>
        </div>

        <div class="key-concept" style="background: var(--danger-light); border-left-color: var(--danger-color);">
            <h3>⚠️ 原教學缺漏的重要內容</h3>
            <p>這些內容在原論文中佔據了完整的章節,但在原教學中完全缺失:</p>
            <ul>
                <li><strong>Section 2.2</strong>: 訓練資料集的詳細組成與處理方式</li>
                <li><strong>Section 4</strong>: 資料污染問題的測量與預防 (完整章節!)</li>
                <li><strong>Related Work</strong>: 相關研究的脈絡</li>
            </ul>
        </div>

        <h2>📚 第一部分:訓練資料集詳解</h2>

        <div class="text-pair">
            <div class="original-text">
                Datasets for language models have rapidly expanded, culminating in the Common Crawl dataset constituting nearly a trillion words. This size of dataset is sufficient to train our largest models without ever updating on the same sequence twice.
            </div>
            <div class="translation">
                語言模型的資料集迅速擴大,最終達到 Common Crawl 資料集,包含近一萬億個單詞。這個資料集的大小足以訓練我們最大的模型,而不需要在同一序列上更新兩次。
            </div>
        </div>

        <div class="key-concept">
            <h4>🎯 訓練資料組成</h4>
            
            <div style="margin: 30px 0; text-align: center;">
                <img src="../images/user_generate_image_20260101095025_f953.png" 
                     alt="GPT-3 訓練資料組成餅圖" 
                     style="max-width: 600px; width: 100%; border-radius: var(--radius-lg); box-shadow: var(--shadow-lg);">
                <p class="caption">
                    <strong>📊 GPT-3 訓練資料組成視覺化</strong><br>
                    Common Crawl 佔 60% (410B tokens) | WebText2 佔 22% (19B tokens)<br>
                    Books 佔 16% (67B tokens) | Wikipedia 佔 3% (3B tokens)<br>
                    總計:<strong>約 300 Billion Tokens</strong>
                </p>
            </div>
            
            <table>
                <thead>
                    <tr>
                        <th>資料集</th>
                        <th>來源</th>
                        <th>大小(Tokens)</th>
                        <th>訓練時採樣權重</th>
                        <th>訓練時實際 Epochs</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>Common Crawl (filtered)</strong></td>
                        <td>網路爬蟲</td>
                        <td>~410B</td>
                        <td>60%</td>
                        <td>0.44</td>
                    </tr>
                    <tr>
                        <td><strong>WebText2</strong></td>
                        <td>Reddit 連結</td>
                        <td>19B</td>
                        <td>22%</td>
                        <td>2.9</td>
                    </tr>
                    <tr>
                        <td><strong>Books1</strong></td>
                        <td>網路書籍</td>
                        <td>12B</td>
                        <td>8%</td>
                        <td>1.9</td>
                    </tr>
                    <tr>
                        <td><strong>Books2</strong></td>
                        <td>網路書籍</td>
                        <td>55B</td>
                        <td>8%</td>
                        <td>0.43</td>
                    </tr>
                    <tr>
                        <td><strong>Wikipedia</strong></td>
                        <td>英文維基</td>
                        <td>3B</td>
                        <td>3%</td>
                        <td>3.4</td>
                    </tr>
                </tbody>
            </table>

            <p><strong>總計: ~300 Billion Tokens (3000 億個 tokens)</strong></p>
        </div>

        <div class="explanation">
            <h4>🔍 關鍵觀察</h4>
            
            <h5>1️⃣ 不按比例採樣</h5>
            <p><strong>重要決策:</strong>高品質資料集被更頻繁地採樣！</p>
            <ul>
                <li>Common Crawl 雖然最大(410B tokens),但只採樣 0.44 epochs</li>
                <li>Wikipedia 雖然最小(3B tokens),但採樣了 3.4 epochs</li>
                <li><strong>理由:</strong>接受少量過擬合,換取更高品質的訓練資料</li>
            </ul>

            <h5>2️⃣ Common Crawl 的三步處理</h5>
            <ol>
                <li><strong>篩選:</strong>基於與高品質語料庫的相似度過濾</li>
                <li><strong>去重:</strong>模糊去重,防止冗餘</li>
                <li><strong>增強:</strong>加入高品質資料集提升多樣性</li>
            </ol>

            <p><strong>原始 vs 處理後:</strong></p>
            <ul>
                <li>原始: 45TB 壓縮文本</li>
                <li>處理後: 570GB (減少 98.7%!)</li>
            </ul>
        </div>

        <div class="analogy">
            <h4>💡 生活類比:食材的精挑細選</h4>
            <p><strong>場景:準備一場盛宴</strong></p>
            
            <p><strong>Common Crawl (網路爬蟲)</strong> = 傳統市場</p>
            <ul>
                <li>什麼都有,但品質參差不齊</li>
                <li>需要仔細挑選、清洗</li>
                <li>45TB → 570GB = 挑掉 98.7% 的劣質品</li>
            </ul>

            <p><strong>高品質資料集</strong> = 有機農場</p>
            <ul>
                <li>Wikipedia = 精選蔬菜</li>
                <li>Books = 優質肉品</li>
                <li>WebText2 = 新鮮海鮮</li>
            </ul>

            <p><strong>採樣策略</strong> = 配方調整</p>
            <ul>
                <li>不是「有什麼用什麼」</li>
                <li>而是「好的多用,差的少用」</li>
                <li>Wikipedia 用 3.4 遍,Common Crawl 只用 0.44 遍!</li>
            </ul>
        </div>

        <h2>⚠️ 第二部分:資料污染問題 (Section 4)</h2>

        <div class="problem">
            <h4>❌ 什麼是資料污染?</h4>
            <p><strong>定義:</strong>測試集的資料意外出現在訓練集中</p>
            
            <p><strong>為什麼是問題?</strong></p>
            <ul>
                <li>模型可能「記住」測試集答案</li>
                <li>評測分數會虛高,不代表真實能力</li>
                <li>就像考試前看到了考題!</li>
            </ul>

            <p><strong>GPT-3 的特殊挑戰:</strong></p>
            <ul>
                <li>訓練資料來自整個網際網路</li>
                <li>很多測試集也是從網路收集的</li>
                <li>模型太大,記憶能力強</li>
            </ul>
        </div>

        <div class="text-pair">
            <div class="original-text">
                Since our training dataset is sourced from the internet, it is possible that our model was trained on some of our benchmark test sets. Accurately detecting test contamination from internet-scale datasets is a new area of research without established best practices.
            </div>
            <div class="translation">
                由於我們的訓練資料集來自網際網路,我們的模型可能在某些基準測試集上進行了訓練。從網際網路規模的資料集中準確檢測測試污染是一個新的研究領域,尚未建立最佳實踐。
            </div>
        </div>

        <div class="explanation">
            <h4>🔬 OpenAI 的處理方法</h4>

            <h5>步驟 1: 主動移除</h5>
            <p>訓練前嘗試移除所有與測試集重疊的資料</p>
            <p><strong>⚠️ 但發生了一個 Bug!</strong></p>
            <ul>
                <li>Bug 導致只移除了「部分」重疊</li>
                <li>重新訓練成本太高 (數百萬美元)</li>
                <li>只能事後分析影響</li>
            </ul>

            <h5>步驟 2: 污染檢測</h5>
            <p><strong>方法:</strong>檢查 13-gram 重疊</p>
            <pre><code>如果測試例子中有連續 13 個詞
出現在訓練集中 → 標記為「可能污染」</code></pre>

            <h5>步驟 3: 建立 Clean 版本</h5>
            <p>移除所有「可能污染」的例子,建立乾淨測試集</p>

            <h5>步驟 4: 對比評測</h5>
            <p>在原始測試集 vs Clean 測試集上分別評測</p>
            <ul>
                <li>如果分數相近 → 污染影響小</li>
                <li>如果分數差很多 → 污染可能影響結果</li>
            </ul>
        </div>

        <div class="figure">
            <img src="images/contamination_graph.png" alt="資料污染分析" style="max-width: 100%; height: auto;">
            <p class="caption">
                <strong>圖:基準測試污染分析</strong><br>
                橫軸:確認乾淨的資料比例<br>
                縱軸:乾淨版本與原版本的效能差異<br>
                <strong>發現:</strong>雖然潛在污染率很高(有些超過 50%),但大多數任務的效能差異很小,
                沒有證據顯示污染程度與效能差異相關。
            </p>
        </div>

        <h2>📊 污染分析結果</h2>

        <div class="key-concept">
            <h4>🔍 重點發現</h4>

            <table>
                <thead>
                    <tr>
                        <th>任務類別</th>
                        <th>污染率</th>
                        <th>效能差異</th>
                        <th>結論</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>閱讀理解</strong><br>(QuAC, SQuAD2, DROP)</td>
                        <td>>90%</td>
                        <td>~0%</td>
                        <td>✅ 只有背景文本,沒有問答對</td>
                    </tr>
                    <tr>
                        <td><strong>德翻英</strong><br>(WMT16)</td>
                        <td>25%</td>
                        <td>1-2 BLEU</td>
                        <td>✅ 只是單語匹配,非翻譯對</td>
                    </tr>
                    <tr style="background: var(--warning-light);">
                        <td><strong>PIQA</strong></td>
                        <td>29%</td>
                        <td>-3%</td>
                        <td>⚠️ 標記星號,可能有影響</td>
                    </tr>
                    <tr style="background: var(--warning-light);">
                        <td><strong>Winograd</strong></td>
                        <td>45%</td>
                        <td>-2.6%</td>
                        <td>⚠️ 標記星號,132 個 schema 在訓練集</td>
                    </tr>
                    <tr>
                        <td><strong>LAMBADA</strong></td>
                        <td>高</td>
                        <td><0.5%</td>
                        <td>✅ 填空格式防止簡單記憶</td>
                    </tr>
                    <tr style="background: var(--danger-light);">
                        <td><strong>語言建模</strong><br>(Wikitext, 1BW, CBT)</td>
                        <td>~100%</td>
                        <td>-</td>
                        <td>❌ 不報告結果</td>
                    </tr>
                </tbody>
            </table>
        </div>

        <div class="solution">
            <h4>✅ OpenAI 的誠實做法</h4>
            <ol>
                <li><strong>透明揭露</strong>:完整章節說明污染問題</li>
                <li><strong>嚴格檢測</strong>:保守的 13-gram 檢測</li>
                <li><strong>對比測試</strong>:建立 clean 版本比較</li>
                <li><strong>標記問題</strong>:PIQA 和 Winograd 加星號</li>
                <li><strong>移除結果</strong>:Wikipedia 語言建模完全不報告</li>
            </ol>

            <p><strong>結論:</strong>雖然有污染,但對大多數結果影響很小</p>
        </div>

        <div class="analogy">
            <h4>💡 生活類比:考試公平性</h4>
            
            <p><strong>場景:期末考</strong></p>

            <p><strong>理想情況:</strong></p>
            <ul>
                <li>考題完全是新的</li>
                <li>學生靠理解能力作答</li>
            </ul>

            <p><strong>資料污染 = 考前看到考題</strong></p>
            <ul>
                <li>高污染率 (90%) = 90% 的題目都看過</li>
                <li>但如果只看過「題幹」沒看過「答案」?</li>
                <li>→ 還是要靠理解才能答對!</li>
            </ul>

            <p><strong>OpenAI 的做法:</strong></p>
            <ol>
                <li>發現有學生可能看過考題 (Bug 導致)</li>
                <li>仔細檢查哪些題目「可能」被看過</li>
                <li>重新用「確定沒看過」的題目測試</li>
                <li>對比分數差異</li>
                <li>誠實標註可能有問題的結果</li>
            </ol>
        </div>

        <div class="key-concept">
            <h4>🎯 為什麼影響小?</h4>

            <p><strong>理論 1: 模型沒有過擬合</strong></p>
            <ul>
                <li>GPT-3 在驗證集上的 loss 仍在下降</li>
                <li>沒有記住訓練資料</li>
                <li>更多是「理解」而非「記憶」</li>
            </ul>

            <p><strong>理論 2: 檢測過於保守</strong></p>
            <ul>
                <li>13-gram 重疊可能只是巧合</li>
                <li>很多「污染」其實是誤報</li>
            </ul>

            <p><strong>理論 3: 測試格式不同</strong></p>
            <ul>
                <li>訓練時看到的是原始文本</li>
                <li>測試時是特定格式 (few-shot prompt)</li>
                <li>不能直接記憶答案</li>
            </ul>
        </div>

        <h2>🤖 AI 體驗連結</h2>

        <div class="analogy">
            <h4>🤖 ChatGPT 會「記住」你的對話嗎?</h4>
            
            <p><strong>你可能擔心:</strong></p>
            <blockquote>
                「我跟 ChatGPT 說的話,會被拿去訓練嗎?」<br>
                「它會記住我的資料嗎?」
            </blockquote>

            <p><strong>實際情況:</strong></p>
            <ul>
                <li><strong>訓練時</strong>: GPT-3 已經訓練完成,不會更新</li>
                <li><strong>對話時</strong>: 只在當前 session 記住,關閉就忘記</li>
                <li><strong>資料收集</strong>: OpenAI 可能收集對話改進未來模型</li>
                <li><strong>隱私保護</strong>: 會去除個人識別資訊</li>
            </ul>

            <p><strong>⚠️ 但要注意:</strong></p>
            <ul>
                <li>不要輸入敏感資訊 (密碼、信用卡)</li>
                <li>不要輸入機密資料</li>
                <li>OpenAI 的隱私政策可能變更</li>
            </ul>
        </div>

        <h2>🎓 總結</h2>

        <div class="key-concept">
            <h4>✅ 本補充章節的核心要點</h4>

            <h5>訓練資料 (Section 2.2)</h5>
            <ol>
                <li><strong>300B tokens</strong>,主要來自 Common Crawl</li>
                <li><strong>嚴格處理</strong>:過濾、去重、增強</li>
                <li><strong>不按比例採樣</strong>:高品質資料多用</li>
                <li><strong>45TB → 570GB</strong>:只保留 1.3% 的高品質資料</li>
            </ol>

            <h5>資料污染 (Section 4)</h5>
            <ol>
                <li><strong>問題嚴重性</strong>:某些測試集污染率 >50%</li>
                <li><strong>影響程度</strong>:大多數任務效能差異 <2%</li>
                <li><strong>誠實處理</strong>:透明揭露、標記問題、移除嚴重案例</li>
                <li><strong>重要發現</strong>:污染率高 ≠ 效能虛高</li>
            </ol>

            <h5>為什麼原教學缺漏?</h5>
            <ul>
                <li>著重於「模型架構」和「驚人結果」</li>
                <li>資料處理細節較為枯燥</li>
                <li>污染分析是「負面」內容</li>
            </ul>

            <h5>為什麼現在補充?</h5>
            <ul>
                <li>完整理解論文需要這些內容</li>
                <li>展示 OpenAI 的科研誠信</li>
                <li>理解實際訓練的複雜性</li>
                <li>學習如何評估模型的真實能力</li>
            </ul>
        </div>

        <div style="background: linear-gradient(135deg, var(--primary-light), var(--secondary-light)); padding: 30px; border-radius: var(--radius-lg); text-align: center; margin: 40px 0;">
            <h3>📊 完整才是真實</h3>
            <p style="font-size: 1.2rem; line-height: 1.8;">
                訓練 GPT-3 不只是「把模型做大」,<br>
                更包括:<br>
                • 精心挑選和處理資料<br>
                • 檢測和處理潛在問題<br>
                • 誠實評估模型能力<br><br>
                這些「不性感」的工作,<br>
                才是成功的關鍵! 🎯
            </p>
        </div>

        <div class="quick-links">
            <a href="index.html" class="quick-link">← 回到 GPT-3 教學首頁</a>
            <a href="03-model-and-training.html" class="quick-link">📖 第 3 頁:模型與訓練</a>
            <a href="../index.html" class="quick-link">🏠 回到三部曲總覽</a>
        </div>
    </div>
</body>
</html>

