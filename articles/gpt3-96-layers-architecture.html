<!DOCTYPE html>
<html lang="zh-TW">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>GPT-3 çš„ 96 å±¤æ¶æ§‹è§£æ</title>
    <link rel="stylesheet" href="../styles/global.css" />
    <link rel="stylesheet" href="../styles/paper-reading.css" />
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script
      id="MathJax-script"
      async
      src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
    ></script>
    <style>
      .architecture-diagram {
        background: white;
        padding: 40px;
        border-radius: var(--radius-lg);
        box-shadow: var(--shadow-lg);
        margin: 30px 0;
      }
      .layer-block {
        border: 3px solid var(--primary-color);
        border-radius: var(--radius-md);
        padding: 20px;
        margin: 10px 0;
        background: var(--primary-light);
      }
      .layer-block h5 {
        margin: 0 0 10px 0;
        color: var(--primary-color);
      }
      .sublayer {
        background: white;
        padding: 12px;
        margin: 8px 0;
        border-left: 4px solid var(--secondary-color);
        border-radius: var(--radius-sm);
      }
      .stack-visual {
        display: flex;
        flex-direction: column;
        gap: 5px;
        margin: 20px 0;
      }
      .mini-layer {
        height: 8px;
        background: linear-gradient(
          90deg,
          var(--primary-color),
          var(--secondary-color)
        );
        border-radius: 2px;
        position: relative;
      }
      .layer-label {
        position: absolute;
        right: -80px;
        top: -4px;
        font-size: 0.8rem;
        color: var(--text-secondary);
      }
      .comparison-table {
        margin: 30px 0;
      }
    </style>
  </head>
  <body>
    <div class="container">
      <div class="breadcrumb">
        <a href="../index.html">ğŸ  é¦–é </a>
        <span>/</span>
        <span class="current">ğŸ”¬ æŠ€è¡“å°ˆé¡Œ: 96å±¤æ¶æ§‹</span>
      </div>

      <h1>ğŸ—ï¸ GPT-3 çš„ 96 å±¤æ¶æ§‹æ·±åº¦è§£æ</h1>

      <div class="key-concept">
        <h3>ğŸ¯ æ ¸å¿ƒå•é¡Œ:96 å±¤æ˜¯ä»€éº¼æ¨£çš„å±¤?</h3>
        <p>
          <strong>ç°¡ç­”:</strong> 96 å±¤
          <strong>Transformer Decoder Block</strong>
        </p>
        <p>æ¯ä¸€å±¤éƒ½åŒ…å«:</p>
        <ul>
          <li>âœ… Masked Self-Attention (é®è”½è‡ªæ³¨æ„åŠ›)</li>
          <li>âœ… Feed-Forward Network (å‰é¥‹ç¥ç¶“ç¶²è·¯)</li>
          <li>âœ… Layer Normalization Ã— 2 (å±¤æ¨™æº–åŒ–)</li>
          <li>âœ… Residual Connections Ã— 2 (æ®˜å·®é€£æ¥)</li>
        </ul>
      </div>

      <h2>ğŸ“ å–®å±¤ Decoder Block çš„å…§éƒ¨çµæ§‹</h2>

      <div style="margin: 40px 0; text-align: center">
        <img
          src="../images/user_generate_image_20260101095049_59d9.png"
          alt="GPT-3 96å±¤æ¶æ§‹è¦–è¦ºåŒ–"
          style="
            max-width: 600px;
            width: 100%;
            border-radius: var(--radius-lg);
            box-shadow: var(--shadow-lg);
          "
        />
        <p class="caption">
          <strong>ğŸ—ï¸ GPT-3 96 å±¤æ¶æ§‹è¦–è¦ºåŒ–</strong><br />
          å‚ç›´å †ç–Šçš„ Transformer Decoder Blocks<br />
          æ¯å€‹ Block:Masked Self-Attention â†’ LayerNorm â†’ FFN â†’ LayerNorm<br />
          ä¸­é–“çœç•¥è™Ÿä»£è¡¨ç¸½å…± <strong>96 å±¤</strong>çš„å †ç–Šï¼
        </p>
      </div>

      <div class="architecture-diagram">
        <h4 style="text-align: center; color: var(--primary-color)">
          ç¬¬ N å±¤ Decoder Block (N = 1 åˆ° 96)
        </h4>

        <div
          style="
            border: 2px dashed var(--text-secondary);
            padding: 20px;
            border-radius: var(--radius-md);
            margin: 20px 0;
          "
        >
          <p style="text-align: center; color: var(--text-secondary)">
            â¬‡ï¸ è¼¸å…¥ (å¾ä¸Šä¸€å±¤æˆ– Embedding å±¤)
          </p>
          <p
            style="
              text-align: center;
              font-family: monospace;
              background: #f1f5f9;
              color: #0f172a;
              padding: 10px;
              border-radius: var(--radius-sm);
            "
          >
            shape: [batch_size, seq_len, d_model]<br />
            = [batch, tokens, 12288]
          </p>
        </div>

        <div class="layer-block">
          <h5>ğŸ”· å­å±¤ 1: Masked Self-Attention</h5>

          <div class="sublayer">
            <strong>1.1 Layer Norm (å‰)</strong>
            <pre style="font-size: 0.9rem; margin: 10px 0">
x_norm = LayerNorm(x)</pre
            >
          </div>

          <div class="sublayer">
            <strong>1.2 Multi-Head Attention</strong>
            <pre style="font-size: 0.9rem; margin: 10px 0">
# 96 å€‹æ³¨æ„åŠ›é ­
Q = W_Q @ x_norm  # Query
K = W_K @ x_norm  # Key  
V = W_V @ x_norm  # Value

# è¨ˆç®—æ³¨æ„åŠ› (å¸¶é®è”½!)
attention_output = MultiHeadAttention(Q, K, V, mask=causal_mask)
                    </pre
            >
            <p style="color: var(--danger-color)">
              <strong>âš ï¸ é—œéµ:Causal Mask</strong>
            </p>
            <p>ç¢ºä¿ token åªèƒ½çœ‹åˆ°ã€Œä¹‹å‰ã€çš„ tokens,ä¸èƒ½çœ‹åˆ°ã€Œä¹‹å¾Œã€çš„!</p>
          </div>

          <div class="sublayer">
            <strong>1.3 Residual Connection</strong>
            <pre style="font-size: 0.9rem; margin: 10px 0">
x = x + attention_output  # æ®˜å·®é€£æ¥</pre
            >
            <p>å°‡åŸå§‹è¼¸å…¥åŠ å›ä¾†,å¹«åŠ©æ¢¯åº¦å‚³æ’­!</p>
          </div>
        </div>

        <div
          style="
            text-align: center;
            margin: 20px 0;
            font-size: 2rem;
            color: var(--text-secondary);
          "
        >
          â¬‡ï¸
        </div>

        <div
          class="layer-block"
          style="
            border-color: var(--secondary-color);
            background: var(--secondary-light);
          "
        >
          <h5 style="color: var(--secondary-color)">
            ğŸ”· å­å±¤ 2: Feed-Forward Network
          </h5>

          <div class="sublayer">
            <strong>2.1 Layer Norm (å‰)</strong>
            <pre style="font-size: 0.9rem; margin: 10px 0">
x_norm = LayerNorm(x)</pre
            >
          </div>

          <div class="sublayer">
            <strong>2.2 å…©å±¤å…¨é€£æ¥ç¶²è·¯</strong>
            <pre style="font-size: 0.9rem; margin: 10px 0">
# ç¬¬ä¸€å±¤:æ“´å±•
hidden = GELU(W_1 @ x_norm + b_1)
# d_model (12288) â†’ d_ff (49152) 
# æ“´å±• 4 å€!

# ç¬¬äºŒå±¤:å£“ç¸®å›ä¾†
ffn_output = W_2 @ hidden + b_2
# d_ff (49152) â†’ d_model (12288)
                    </pre
            >
            <p><strong>ä½œç”¨:</strong>æ¯å€‹ token ç¨ç«‹è™•ç†,å¢åŠ éç·šæ€§è®Šæ›!</p>
          </div>

          <div class="sublayer">
            <strong>2.3 Residual Connection</strong>
            <pre style="font-size: 0.9rem; margin: 10px 0">
x = x + ffn_output  # æ®˜å·®é€£æ¥</pre
            >
          </div>
        </div>

        <div
          style="
            border: 2px dashed var(--text-secondary);
            padding: 20px;
            border-radius: var(--radius-md);
            margin: 20px 0;
          "
        >
          <p style="text-align: center; color: var(--text-secondary)">
            â¬‡ï¸ è¼¸å‡º (å‚³çµ¦ä¸‹ä¸€å±¤)
          </p>
          <p
            style="
              text-align: center;
              font-family: monospace;
              background: #f1f5f9;
              color: #0f172a;
              padding: 10px;
              border-radius: var(--radius-sm);
            "
          >
            shape: [batch_size, seq_len, d_model]<br />
            = [batch, tokens, 12288]
          </p>
        </div>
      </div>

      <h2>ğŸ—ï¸ å®Œæ•´çš„ 96 å±¤å †ç–Š</h2>

      <div class="architecture-diagram">
        <h4 style="text-align: center">GPT-3 175B å®Œæ•´æ¶æ§‹</h4>

        <div
          style="
            background: var(--accent-light);
            padding: 20px;
            border-radius: var(--radius-md);
            margin: 20px 0;
          "
        >
          <h5 style="margin-top: 0">ğŸ“¥ è¼¸å…¥éšæ®µ</h5>
          <div
            style="
              background: white;
              padding: 15px;
              border-radius: var(--radius-sm);
              margin: 10px 0;
            "
          >
            <strong>1. Token Embedding</strong>
            <pre style="font-size: 0.85rem">
input_ids: [1, 234, 5678, ...]  # Token IDs
â†’ embeddings: [..., 12288 ç¶­å‘é‡, ...]</pre
            >
          </div>
          <div
            style="
              background: white;
              padding: 15px;
              border-radius: var(--radius-sm);
              margin: 10px 0;
            "
          >
            <strong>2. Positional Encoding</strong>
            <pre style="font-size: 0.85rem">
learned_pos: [0â†’12288, 1â†’12288, ..., 2047â†’12288]
x = token_emb + pos_emb</pre
            >
            <p style="font-size: 0.9rem; color: var(--text-secondary)">
              GPT-3 ä½¿ç”¨<strong>å­¸ç¿’å¼</strong>ä½ç½®ç·¨ç¢¼,æœ€å¤šæ”¯æ´ 2048 å€‹ tokens
            </p>
          </div>
        </div>

        <div
          style="
            background: var(--primary-light);
            padding: 20px;
            border-radius: var(--radius-md);
            margin: 20px 0;
          "
        >
          <h5 style="margin-top: 0">ğŸ” 96 å±¤ Transformer Decoder</h5>

          <div class="stack-visual">
            <div class="mini-layer" style="background: var(--danger-color)">
              <span class="layer-label">ç¬¬ 96 å±¤ â­</span>
            </div>
            <div class="mini-layer"></div>
            <div class="mini-layer"></div>
            <div class="mini-layer"></div>
            <div
              style="
                text-align: center;
                color: var(--text-secondary);
                font-size: 1.5rem;
                margin: 5px 0;
              "
            >
              ...
            </div>
            <div class="mini-layer">
              <span class="layer-label">ç¬¬ 50 å±¤</span>
            </div>
            <div
              style="
                text-align: center;
                color: var(--text-secondary);
                font-size: 1.5rem;
                margin: 5px 0;
              "
            >
              ...
            </div>
            <div class="mini-layer">
              <span class="layer-label">ç¬¬ 10 å±¤</span>
            </div>
            <div class="mini-layer"></div>
            <div class="mini-layer"></div>
            <div class="mini-layer" style="background: var(--success-color)">
              <span class="layer-label">ç¬¬ 1 å±¤ ğŸš€</span>
            </div>
          </div>

          <p style="text-align: center; font-size: 1.1rem; margin-top: 20px">
            <strong>æ¯ä¸€å±¤éƒ½åŸ·è¡Œç›¸åŒçš„æ“ä½œ:</strong><br />
            Masked Self-Attention â†’ Add & Norm â†’ FFN â†’ Add & Norm
          </p>
        </div>

        <div
          style="
            background: var(--success-light);
            padding: 20px;
            border-radius: var(--radius-md);
            margin: 20px 0;
          "
        >
          <h5 style="margin-top: 0">ğŸ“¤ è¼¸å‡ºéšæ®µ</h5>
          <div
            style="
              background: white;
              padding: 15px;
              border-radius: var(--radius-sm);
              margin: 10px 0;
            "
          >
            <strong>1. Final Layer Norm</strong>
            <pre style="font-size: 0.85rem">
x_final = LayerNorm(x_from_layer_96)</pre
            >
          </div>
          <div
            style="
              background: white;
              padding: 15px;
              border-radius: var(--radius-sm);
              margin: 10px 0;
            "
          >
            <strong>2. Language Model Head</strong>
            <pre style="font-size: 0.85rem">
logits = W_lm @ x_final  # [vocab_size, d_model]
# 12288 â†’ 50257 (è©å½™è¡¨å¤§å°)

probabilities = Softmax(logits)
next_token = argmax(probabilities)</pre
            >
          </div>
        </div>
      </div>

      <h2>ğŸ“Š ä¸‰å¤§æ¨¡å‹çš„æ¶æ§‹å°æ¯”</h2>

      <div style="margin: 40px 0">
        <img
          src="../images/user_generate_image_20260101231745_bd01.png"
          alt="Transformer vs GPT-3 æ¶æ§‹å°æ¯”"
          style="
            max-width: 100%;
            border-radius: var(--radius-lg);
            box-shadow: var(--shadow-lg);
          "
        />
        <p class="caption">
          <strong>ğŸ” é—œéµå·®ç•°ï¼šåŸå§‹ Transformer vs GPT-3</strong><br />
          å·¦ï¼šEncoder-Decoder æ¶æ§‹ï¼ˆé›™å‘ + å–®å‘ï¼‰<br />
          å³ï¼šDecoder-Only æ¶æ§‹ï¼ˆç´”å–®å‘ï¼Œä½†å †ç–Š 96 å±¤ï¼ï¼‰
        </p>
      </div>

      <h2>ğŸ†š è£œå……èªªæ˜ 01ï¼šèˆ‡åŸå§‹ Transformer çš„é—œéµå·®ç•°</h2>

      <div class="explanation">
        <h4>ğŸ”‘ æ ¸å¿ƒå·®ç•°ï¼šEncoder-Decoder vs Decoder-Only</h4>

        <table>
          <thead>
            <tr>
              <th>ç‰¹æ€§</th>
              <th>åŸå§‹ Transformer (2017)</th>
              <th>GPT-3 (2020)</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td><strong>1ï¸âƒ£ æ¶æ§‹çµ„æˆ</strong></td>
              <td>
                âœ… <strong>Encoder</strong> (6 å±¤)<br />
                âœ… <strong>Decoder</strong> (6 å±¤)<br />
                âœ… <strong>Cross-Attention</strong> é€£æ¥å…©è€…
              </td>
              <td>
                âŒ æ²’æœ‰ Encoder<br />
                âœ… <strong>åªæœ‰ Decoder</strong> (96 å±¤)<br />
                âŒ æ²’æœ‰ Cross-Attention
              </td>
            </tr>
            <tr>
              <td><strong>2ï¸âƒ£ Attention æ©Ÿåˆ¶</strong></td>
              <td>
                <strong>Encoder:</strong> é›™å‘ Self-Attention<br />
                (å¯ä»¥çœ‹åˆ°å‰å¾Œæ‰€æœ‰ tokens)<br /><br />
                <strong>Decoder:</strong> å–®å‘ Masked Self-Attention<br />
                (åªèƒ½çœ‹åˆ°ä¹‹å‰çš„ tokens)
              </td>
              <td>
                <strong>å…¨éƒ¨:</strong> å–®å‘ Masked Self-Attention<br />
                (æ°¸é åªèƒ½çœ‹åˆ°ä¹‹å‰çš„ tokens)<br /><br />
                é€™å°±æ˜¯ã€Œè‡ªå›æ­¸ (Autoregressive)ã€
              </td>
            </tr>
            <tr>
              <td><strong>3ï¸âƒ£ è¼¸å…¥æ–¹å¼</strong></td>
              <td>
                <strong>Encoder:</strong> å®Œæ•´è¼¸å…¥å¥å­<br />
                <strong>Decoder:</strong> é€å­—ç”Ÿæˆè¼¸å‡º
              </td>
              <td>
                <strong>å…¨éƒ¨:</strong> é€å­—è™•ç†èˆ‡ç”Ÿæˆ<br />
                è¼¸å…¥ä¹Ÿæ˜¯ä¸€å€‹ token ä¸€å€‹ token å–‚é€²å»
              </td>
            </tr>
            <tr>
              <td><strong>4ï¸âƒ£ è¨­è¨ˆç›®æ¨™</strong></td>
              <td>
                ğŸ¯ <strong>Seq2Seq ä»»å‹™</strong><br />
                ç¿»è­¯ï¼šè‹±æ–‡ â†’ ä¸­æ–‡<br />
                æ‘˜è¦ï¼šé•·æ–‡ â†’ çŸ­æ–‡
              </td>
              <td>
                ğŸ¯ <strong>Language Modeling</strong><br />
                çµ¦å‰æ–‡ â†’ é æ¸¬ä¸‹ä¸€å€‹å­—<br />
                (ä½†å¯ä»¥é€é prompt åšä»»ä½•ä»»å‹™!)
              </td>
            </tr>
            <tr>
              <td><strong>5ï¸âƒ£ Position Encoding</strong></td>
              <td>
                <strong>å›ºå®šå¼ (Sinusoidal)</strong><br />
                sin/cos å‡½æ•¸è¨ˆç®—<br />
                æ”¯æ´ä»»æ„é•·åº¦
              </td>
              <td>
                <strong>å­¸ç¿’å¼ (Learned)</strong><br />
                åƒæ•¸å¯è¨“ç·´<br />
                <strong>é™åˆ¶:</strong> æœ€å¤š 2048 tokens
              </td>
            </tr>
          </tbody>
        </table>
      </div>

      <div class="key-concept">
        <h4>ğŸ’¡ ç‚ºä»€éº¼ GPT-3 æ‹¿æ‰ Encoderï¼Ÿ</h4>

        <p><strong>1. ç°¡åŒ–æ¶æ§‹ = æ›´å¥½æ“´å±•</strong></p>
        <ul>
          <li>Decoder-Only æ›´å®¹æ˜“å †ç–Šåˆ° 96 å±¤</li>
          <li>ä¸éœ€è¦ç®¡ç† Encoder-Decoder ä¹‹é–“çš„é€£æ¥</li>
          <li>è¨“ç·´æ›´ç©©å®š</li>
        </ul>

        <p><strong>2. Language Modeling å¤ å¼·å¤§</strong></p>
        <ul>
          <li>ã€Œé æ¸¬ä¸‹ä¸€å€‹å­—ã€é€™å€‹ç°¡å–®ä»»å‹™ï¼Œå­¸æœƒäº†å°±èƒ½åšæ‰€æœ‰äº‹</li>
          <li>é€é prompt engineeringï¼Œå¯ä»¥æ¨¡æ“¬ç¿»è­¯ã€æ‘˜è¦ã€å•ç­”ç­‰</li>
          <li>ä¸éœ€è¦å°ˆé–€çš„ Encoder ä¾†ã€Œç†è§£ã€è¼¸å…¥</li>
        </ul>

        <p><strong>3. è‡ªå›æ­¸çš„å„ªå‹¢</strong></p>
        <ul>
          <li>ç”Ÿæˆéç¨‹è‡ªç„¶æµæš¢ï¼ˆä¸€å€‹å­—æ¥ä¸€å€‹å­—ï¼‰</li>
          <li>å¯ä»¥æ§åˆ¶ç”Ÿæˆé•·åº¦ï¼ˆæƒ³ç”Ÿæˆå¤šé•·å°±å¤šé•·ï¼‰</li>
          <li>ç¬¦åˆäººé¡å¯«ä½œçš„ç¿’æ…£</li>
        </ul>
      </div>

      <div class="analogy">
        <h4>ğŸ¬ ç”Ÿæ´»é¡æ¯”ï¼šé›»å½±åŠ‡æœ¬å‰µä½œ</h4>

        <p><strong>åŸå§‹ Transformer (Encoder-Decoder) = ç¿»è­¯æ©Ÿ</strong></p>
        <ul>
          <li><strong>Encoder:</strong> å…ˆè®€å®Œæ•´éƒ¨è‹±æ–‡åŠ‡æœ¬ï¼Œå®Œå…¨ç†è§£</li>
          <li><strong>Decoder:</strong> æ ¹æ“šç†è§£ï¼Œé€å¥ç¿»è­¯æˆä¸­æ–‡</li>
          <li><strong>é©åˆ:</strong> æœ‰æ˜ç¢ºè¼¸å…¥â†’è¼¸å‡ºçš„ä»»å‹™</li>
        </ul>

        <p><strong>GPT-3 (Decoder-Only) = å³èˆˆä½œå®¶</strong></p>
        <ul>
          <li>çµ¦ä»–ä¸€å€‹é–‹é ­ï¼šã€Œåœ¨ä¸€å€‹é»‘æš—çš„å¤œæ™š...ã€</li>
          <li>ä»–æ ¹æ“šã€Œç›®å‰ç‚ºæ­¢çš„æ‰€æœ‰æ–‡å­—ã€ï¼ŒçŒœä¸‹ä¸€å€‹å­—</li>
          <li>ç„¶å¾ŒæŠŠæ–°å­—åŠ é€²å»ï¼Œå†çŒœä¸‹ä¸€å€‹å­—</li>
          <li><strong>é©åˆ:</strong> å‰µé€ æ€§ä»»å‹™ã€é–‹æ”¾å¼ç”Ÿæˆ</li>
        </ul>
      </div>

      <h2>ğŸ“Š ä¸‰å¤§æ¨¡å‹çš„æ¶æ§‹å°æ¯”</h2>

      <div class="comparison-table">
        <table>
          <thead>
            <tr>
              <th>ç‰¹æ€§</th>
              <th>Transformer (2017)</th>
              <th>BERT Large (2018)</th>
              <th>GPT-3 175B (2020)</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td><strong>æ¶æ§‹é¡å‹</strong></td>
              <td>Encoder + Decoder</td>
              <td>Encoder Only</td>
              <td><strong>Decoder Only</strong></td>
            </tr>
            <tr>
              <td><strong>å±¤æ•¸</strong></td>
              <td>6 + 6 = 12</td>
              <td>24</td>
              <td><strong>96 â­</strong></td>
            </tr>
            <tr>
              <td><strong>d_model</strong></td>
              <td>512</td>
              <td>1024</td>
              <td><strong>12,288</strong></td>
            </tr>
            <tr>
              <td><strong>æ³¨æ„åŠ›é ­</strong></td>
              <td>8</td>
              <td>16</td>
              <td><strong>96</strong></td>
            </tr>
            <tr>
              <td><strong>d_ff</strong></td>
              <td>2048</td>
              <td>4096</td>
              <td><strong>49,152</strong></td>
            </tr>
            <tr>
              <td><strong>åƒæ•¸é‡</strong></td>
              <td>~65M</td>
              <td>340M</td>
              <td><strong>175B</strong></td>
            </tr>
            <tr>
              <td><strong>æ¯å±¤åƒæ•¸</strong></td>
              <td>~5M</td>
              <td>~14M</td>
              <td><strong>~1.8B</strong></td>
            </tr>
          </tbody>
        </table>
      </div>

      <h2>ğŸ’¡ ç‚ºä»€éº¼æ˜¯ 96 å±¤?</h2>

      <div class="explanation">
        <h4>ğŸ¯ å±¤æ•¸çš„æ¼”é€²é‚è¼¯</h4>

        <p><strong>ç¶“é©—æ³•å‰‡:</strong></p>
        <ul>
          <li>æ›´æ·± = æ›´è¤‡é›œçš„ç‰¹å¾µæå–</li>
          <li>æ·ºå±¤:å­¸ç¿’åŸºæœ¬èªæ³•ã€è©æ€§</li>
          <li>ä¸­å±¤:å­¸ç¿’å¥å­çµæ§‹ã€èªç¾©é—œä¿‚</li>
          <li>æ·±å±¤:å­¸ç¿’æŠ½è±¡æ¦‚å¿µã€æ¨ç†èƒ½åŠ›</li>
        </ul>

        <h5>å¯¦é©—ç™¼ç¾</h5>
        <table>
          <thead>
            <tr>
              <th>å±¤æ•¸</th>
              <th>æ¨¡å‹</th>
              <th>è§€å¯Ÿ</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>6-12</td>
              <td>Transformer, GPT-1</td>
              <td>åŸºæœ¬èªè¨€ç†è§£</td>
            </tr>
            <tr>
              <td>24</td>
              <td>BERT Large, GPT-2</td>
              <td>æ›´å¥½çš„ä¸Šä¸‹æ–‡ç†è§£</td>
            </tr>
            <tr>
              <td>48</td>
              <td>T5-11B</td>
              <td>é–‹å§‹å‡ºç¾ emergent abilities</td>
            </tr>
            <tr style="background: var(--primary-light)">
              <td><strong>96</strong></td>
              <td><strong>GPT-3 175B</strong></td>
              <td><strong>Few-shot learning, æ¨ç†èƒ½åŠ›è³ªè®Š</strong></td>
            </tr>
          </tbody>
        </table>
      </div>

      <div class="analogy">
        <h4>ğŸ¢ ç”Ÿæ´»é¡æ¯”:å¤§æ¨“çš„æ¨“å±¤</h4>

        <div style="text-align: center; margin: 20px 0">
          <img
            src="../images/user_generate_image_20260102035516_c9c2.png"
            alt="96å±¤æ‘©å¤©å¤§æ¨“é¡æ¯”"
            style="
              max-width: 100%;
              border-radius: var(--radius-md);
              box-shadow: var(--shadow-sm);
            "
          />
        </div>

        <p><strong>å ´æ™¯:æ€è€ƒéç¨‹</strong></p>

        <div style="margin: 20px 0">
          <p><strong>6 å±¤ (Transformer)</strong> = 6 å±¤æ¨“çš„å…¬å¯“</p>
          <p>é©åˆåŸºæœ¬ç”Ÿæ´»,ä½†è¦–é‡æœ‰é™</p>
        </div>

        <div style="margin: 20px 0">
          <p><strong>24 å±¤ (BERT)</strong> = 24 å±¤çš„å•†è¾¦å¤§æ¨“</p>
          <p>æ¯å±¤è² è²¬ä¸åŒéƒ¨é–€,å”åŒåˆä½œ</p>
        </div>

        <div style="margin: 20px 0">
          <p><strong>96 å±¤ (GPT-3)</strong> = 96 å±¤çš„æ‘©å¤©å¤§æ¨“ ğŸ™ï¸</p>
          <ul>
            <li>åº•å±¤ (1-20):è™•ç†åŸºç¤è¼¸å…¥(èªæ³•ã€è©æ€§)</li>
            <li>ä¸­å±¤ (21-60):ç†è§£èªç¾©å’Œé—œä¿‚</li>
            <li>é«˜å±¤ (61-96):æŠ½è±¡æ¨ç†å’Œå‰µé€ </li>
          </ul>
          <p>è¶Šé«˜çš„æ¨“å±¤ â†’ è¦–é‡è¶Šå»£ â†’ æ€è€ƒè¶ŠæŠ½è±¡!</p>
        </div>
      </div>

      <h2>ğŸ”¬ å±¤èˆ‡å±¤ä¹‹é–“ç™¼ç”Ÿä»€éº¼?</h2>

      <div class="explanation">
        <h4>è³‡è¨Šçš„é€å±¤ç²¾ç…‰</h4>

        <pre
          style="
            background: #f8fafc;
            color: #0f172a;
            padding: 20px;
            border-radius: var(--radius-md);
            line-height: 1.8;
          "
        >
<strong>è¼¸å…¥:</strong> "The cat sat on the"

<strong>ç¬¬ 1-10 å±¤:</strong> è­˜åˆ¥è©æ€§
- "The" = å† è©
- "cat" = åè©
- "sat" = å‹•è©(éå»å¼)
- "on" = ä»‹ç³»è©
- "the" = å† è©

<strong>ç¬¬ 11-30 å±¤:</strong> ç†è§£èªæ³•çµæ§‹
- "The cat" = ä¸»èª
- "sat on the X" = å‹•ä½œ + ä½ç½®é—œä¿‚
- é æœŸä¸‹ä¸€å€‹è©:åœ°é»åè©

<strong>ç¬¬ 31-60 å±¤:</strong> èªç¾©ç†è§£
- å ´æ™¯:è²“ååœ¨æŸè™•
- å¸¸è¦‹æ­é…:"mat", "floor", "table"
- æ’é™¤ä¸åˆç†é¸é …:"sky", "water"

<strong>ç¬¬ 61-90 å±¤:</strong> ä¸Šä¸‹æ–‡æ¨ç†
- å¦‚æœå‰æ–‡æåˆ°"living room" â†’ "sofa", "carpet"
- å¦‚æœå‰æ–‡æåˆ°"garden" â†’ "fence", "grass"

<strong>ç¬¬ 91-96 å±¤:</strong> æœ€çµ‚æ±ºç­–
- ç¶œåˆæ‰€æœ‰è³‡è¨Š
- è¨ˆç®—æ¯å€‹å€™é¸è©çš„æ©Ÿç‡
- <strong>è¼¸å‡º: "mat" (æ©Ÿç‡æœ€é«˜)</strong>
            </pre>
      </div>

      <h2>âš ï¸ 96 å±¤çš„æŒ‘æˆ°</h2>

      <div class="problem">
        <h4>âŒ è¶…æ·±ç¶²è·¯çš„å•é¡Œ</h4>

        <table>
          <thead>
            <tr>
              <th>å•é¡Œ</th>
              <th>åŸå› </th>
              <th>GPT-3 çš„è§£æ±ºæ–¹æ¡ˆ</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td><strong>æ¢¯åº¦æ¶ˆå¤±</strong></td>
              <td>96 å±¤å‚³æ’­æœƒè¡°æ¸›</td>
              <td>âœ… Residual Connection<br />âœ… Layer Norm</td>
            </tr>
            <tr>
              <td><strong>è¨“ç·´ä¸ç©©å®š</strong></td>
              <td>æ·±åº¦ç¶²è·¯å®¹æ˜“ç™¼æ•£</td>
              <td>âœ… å°å¿ƒçš„åˆå§‹åŒ–<br />âœ… å­¸ç¿’ç‡èª¿åº¦</td>
            </tr>
            <tr>
              <td><strong>è¨˜æ†¶é«”çˆ†ç‚¸</strong></td>
              <td>éœ€è¦å„²å­˜æ¯å±¤çš„æ¿€æ´»å€¼</td>
              <td>âœ… Gradient Checkpointing<br />âœ… Model Parallelism</td>
            </tr>
            <tr>
              <td><strong>æ¨ç†é€Ÿåº¦æ…¢</strong></td>
              <td>å¿…é ˆä¾åºåŸ·è¡Œ 96 å±¤</td>
              <td>âš ï¸ ç„¡æ³•å®Œå…¨è§£æ±º<br />éœ€è¦å¤§é‡ GPU</td>
            </tr>
          </tbody>
        </table>
      </div>

      <h2>ğŸ“ é—œéµæŠ€è¡“:Residual Connection</h2>

      <div class="explanation">
        <h4>ç‚ºä»€éº¼ 96 å±¤ä¸æœƒæ¢¯åº¦æ¶ˆå¤±?</h4>

        <p><strong>æ²’æœ‰ Residual Connection:</strong></p>
        <pre
          style="
            background: white;
            color: #0f172a;
            padding: 15px;
            border-radius: var(--radius-sm);
          "
        >
xâ‚ = Layerâ‚(xâ‚€)
xâ‚‚ = Layerâ‚‚(xâ‚)
xâ‚ƒ = Layerâ‚ƒ(xâ‚‚)
...
xâ‚‰â‚† = Layerâ‚‰â‚†(xâ‚‰â‚…)

æ¢¯åº¦å‚³æ’­: âˆ‚L/âˆ‚xâ‚€ = âˆ‚L/âˆ‚xâ‚‰â‚† Ã— âˆ‚xâ‚‰â‚†/âˆ‚xâ‚‰â‚… Ã— ... Ã— âˆ‚xâ‚/âˆ‚xâ‚€
                    â†‘ 96 å€‹å°æ–¼ 1 çš„æ•¸ç›¸ä¹˜ â†’ æ¥è¿‘ 0!
            </pre
        >

        <p><strong>æœ‰ Residual Connection:</strong></p>
        <pre
          style="
            background: white;
            color: #0f172a;
            padding: 15px;
            border-radius: var(--radius-sm);
          "
        >
xâ‚ = xâ‚€ + Layerâ‚(xâ‚€)
xâ‚‚ = xâ‚ + Layerâ‚‚(xâ‚)
xâ‚ƒ = xâ‚‚ + Layerâ‚ƒ(xâ‚‚)
...
xâ‚‰â‚† = xâ‚‰â‚… + Layerâ‚‰â‚†(xâ‚‰â‚…)

æ¢¯åº¦å‚³æ’­: âˆ‚L/âˆ‚xâ‚€ = âˆ‚L/âˆ‚xâ‚‰â‚† Ã— (1 + âˆ‚Layer/âˆ‚x)
                    â†‘ ç¸½æœ‰ä¸€æ¢ã€Œé«˜é€Ÿå…¬è·¯ã€ç›´é”é ‚å±¤!
            </pre
        >

        <p><strong>çµæœ:</strong>æ¢¯åº¦å¯ä»¥é †åˆ©å‚³å›ç¬¬ 1 å±¤,è¨“ç·´ç©©å®š!</p>
      </div>

      <h2>ğŸ¯ ç¸½çµ</h2>

      <div style="margin: 40px 0">
        <img
          src="../images/user_generate_image_20260101231814_4465.png"
          alt="GPT-3 æ¨ç†æµç¨‹"
          style="
            max-width: 100%;
            border-radius: var(--radius-lg);
            box-shadow: var(--shadow-lg);
          "
        />
        <p class="caption">
          <strong>ğŸ”„ GPT-3 çš„è‡ªå›æ­¸ç”Ÿæˆæµç¨‹</strong><br />
          å¾ç”¨æˆ¶è¼¸å…¥ â†’ Tokenize â†’ 96å±¤è™•ç† â†’ é æ¸¬æ©Ÿç‡ â†’ é¸å­— â†’ å¾ªç’°<br />
          æ¯æ¬¡åªç”Ÿæˆä¸€å€‹ tokenï¼Œç„¶å¾ŒæŠŠå®ƒåŠ å›è¼¸å…¥ï¼Œé‡æ–°é æ¸¬ä¸‹ä¸€å€‹ï¼
        </p>
      </div>

      <div
        class="key-concept"
        style="
          background: linear-gradient(
            135deg,
            var(--primary-light),
            var(--accent-light)
          );
          padding: 30px;
          border-radius: var(--radius-lg);
          margin: 40px 0;
          border: 3px solid var(--primary-color);
        "
      >
        <h3 style="text-align: center; color: var(--primary-color)">
          ğŸ” æ·±å…¥æ¢è¨
        </h3>
        <p
          style="
            font-size: 1.15rem;
            line-height: 1.8;
            text-align: center;
            margin: 20px 0;
          "
        >
          æƒ³äº†è§£ <strong>è¨“ç·´èˆ‡æ¨ç†æ™‚ tokens å¦‚ä½•è¼¸å…¥</strong>ï¼Ÿ<br />
          æƒ³çŸ¥é“ç‚ºä»€éº¼ ChatGPT æœƒ<strong>ä¸€å€‹å­—ä¸€å€‹å­—</strong>ç”Ÿæˆå›ç­”ï¼Ÿ<br /><br />
          ğŸ‘‰
          <a
            href="gpt3-training-vs-inference.html"
            style="
              background: var(--primary-color);
              color: white;
              padding: 15px 30px;
              border-radius: var(--radius-md);
              text-decoration: none;
              font-weight: bold;
              display: inline-block;
              margin-top: 10px;
            "
            >é»æ“ŠæŸ¥çœ‹ï¼šè¨“ç·´ vs æ¨ç†å®Œæ•´è§£æ â†’</a
          >
        </p>
      </div>

      <h2>ğŸ¯ ç¸½çµ</h2>

      <div class="key-concept">
        <h4>âœ… GPT-3 çš„ 96 å±¤æ¶æ§‹ - å®Œæ•´ç†è§£</h4>

        <ol>
          <li>
            <strong>æ¶æ§‹é¸æ“‡ï¼šDecoder-Only</strong>
            <p>
              èˆ‡åŸå§‹ Transformer ä¸åŒï¼ŒGPT-3 åªç”¨ Decoderï¼Œæ²’æœ‰ Encoderï¼<br />
              æ›´ç°¡å–®ã€æ›´å®¹æ˜“æ“´å±•åˆ° 96 å±¤ã€‚
            </p>
          </li>
          <li>
            <strong>æ¯å±¤éƒ½æ˜¯ Transformer Decoder Block</strong>
            <p>Masked Self-Attention + Feed-Forward Network</p>
          </li>
          <li>
            <strong>å±¤èˆ‡å±¤å®Œå…¨ç›¸åŒ</strong>
            <p>åªæ˜¯åƒæ•¸ä¸åŒï¼Œçµæ§‹ç›¸åŒ</p>
          </li>
          <li>
            <strong>è³‡è¨Šé€å±¤ç²¾ç…‰</strong>
            <p>å¾åŸºç¤èªæ³• â†’ èªç¾©ç†è§£ â†’ æŠ½è±¡æ¨ç†</p>
          </li>
          <li>
            <strong>è‡ªå›æ­¸ç”Ÿæˆï¼šä¸€å€‹å­—ä¸€å€‹å­—ä¾†</strong>
            <p>
              æ¯ç”Ÿæˆä¸€å€‹å­—ï¼Œå°±æŠŠå®ƒåŠ å›è¼¸å…¥ï¼Œé‡æ–°è·‘ä¸€æ¬¡ 96 å±¤ï¼<br />
              é€™å°±æ˜¯ç‚ºä»€éº¼ ChatGPT å›ç­”æ™‚æœƒã€Œæ‰“å­—ã€çš„æ•ˆæœã€‚
            </p>
          </li>
          <li>
            <strong>é—œéµæŠ€è¡“è®“æ·±åº¦æˆç‚ºå¯èƒ½</strong>
            <p>Residual Connection + Layer Norm</p>
          </li>
          <li>
            <strong>96 å±¤ = è³ªè®Šçš„é—œéµ</strong>
            <p>å‡ºç¾ few-shot learning ç­‰ emergent abilitiesï¼</p>
          </li>
        </ol>

        <div
          style="
            background: var(--danger-light);
            padding: 20px;
            border-radius: var(--radius-md);
            margin-top: 30px;
          "
        >
          <h5 style="color: var(--danger-color)">âš¡ å…©å¤§æ ¸å¿ƒæ¦‚å¿µ</h5>
          <p>
            <strong>1. Decoder-Only æ¶æ§‹ï¼š</strong>ä¸éœ€è¦
            Encoderï¼Œç´”ç²¹çš„èªè¨€å»ºæ¨¡
          </p>
          <p>
            <strong>2. Autoregressive ç”Ÿæˆï¼š</strong>ä¸€å€‹ token ä¸€å€‹ token
            é æ¸¬ï¼Œç„¡æ³•ä¸¦è¡Œ
          </p>
          <p style="margin-top: 15px; font-size: 1.1rem">
            é€™å…©å€‹ç‰¹æ€§è®“ GPT-3 èƒ½åšåˆ°ã€Œçœ‹èµ·ä¾†åƒåœ¨æ€è€ƒã€çš„æ•ˆæœï¼ğŸ§ 
          </p>
        </div>
      </div>

      <div
        style="
          background: linear-gradient(
            135deg,
            var(--primary-light),
            var(--purple-light)
          );
          padding: 30px;
          border-radius: var(--radius-lg);
          text-align: center;
          margin: 40px 0;
        "
      >
        <h3>ğŸ—ï¸ 96 å±¤æ‘©å¤©å¤§æ¨“</h3>
        <p style="font-size: 1.2rem; line-height: 1.8">
          ä¸åªæ˜¯æ•¸é‡ä¸Šçš„å †ç–Š,<br />
          æ›´æ˜¯<strong>è³ªé‡</strong>çš„çªç ´!<br /><br />
          å¾ã€Œæ‡‚èªè¨€ã€â†’ åˆ°ã€Œæœƒæ€è€ƒã€â†’ åˆ°ã€Œèƒ½å‰µé€ ã€<br />
          é€™å°±æ˜¯æ·±åº¦çš„åŠ›é‡! ğŸš€
        </p>
      </div>

      <div class="quick-links">
        <a href="../index.html" class="quick-link">â† å›åˆ°ä¸‰éƒ¨æ›²ç¸½è¦½</a>
        <a href="model-dimension-evolution.html" class="quick-link"
          >â† ä¸Šä¸€å°ˆé¡Œ:ç¶­åº¦æ¼”é€²</a
        >
        <a href="gpt3-training-vs-inference.html" class="quick-link"
          >ä¸‹ä¸€ç« ï¼šè¨“ç·´ vs æ¨ç† â†’</a
        >
      </div>

      <div class="quick-links" style="margin-top: 20px">
        <a href="../gpt3-tutorial/index.html" class="quick-link"
          >ğŸ“– GPT-3 æ•™å­¸ç¸½è¦½</a
        >
        <a href="tokenizer-embedding-explained.html" class="quick-link"
          >ğŸ”¤ Tokenizer å°ˆé¡Œ</a
        >
        <a
          href="../transformer-tutorial/03-2-model-architecture-components.html"
          class="quick-link"
          >ğŸ“– Transformer çµ„ä»¶è©³è§£</a
        >
      </div>
    </div>
  </body>
</html>
