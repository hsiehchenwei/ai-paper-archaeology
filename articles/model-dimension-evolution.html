<!DOCTYPE html>
<html lang="zh-TW">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>模型維度演進:從 Transformer 到 GPT-3</title>
    <link rel="stylesheet" href="../styles/global.css">
    <link rel="stylesheet" href="../styles/paper-reading.css">
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <style>
        .dimension-visual {
            background: white;
            padding: 30px;
            border-radius: var(--radius-lg);
            margin: 20px 0;
            box-shadow: var(--shadow-md);
        }
        .vector-box {
            display: inline-block;
            padding: 8px 16px;
            border: 2px solid var(--primary-color);
            border-radius: var(--radius-md);
            margin: 5px;
            background: var(--primary-light);
            font-family: 'Courier New', monospace;
        }
        .comparison-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 20px;
            margin: 30px 0;
        }
        .model-card {
            background: white;
            padding: 24px;
            border-radius: var(--radius-lg);
            box-shadow: var(--shadow-md);
            border-top: 4px solid var(--primary-color);
        }
        .dimension-bar {
            height: 30px;
            background: linear-gradient(90deg, var(--primary-color), var(--secondary-color));
            border-radius: var(--radius-sm);
            position: relative;
            margin: 10px 0;
        }
        .dimension-label {
            position: absolute;
            right: 10px;
            top: 50%;
            transform: translateY(-50%);
            color: white;
            font-weight: bold;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="breadcrumb">
            <a href="../index.html">🏠 首頁</a>
            <span>/</span>
            <span class="current">🔬 技術專題: 模型維度演進</span>
        </div>

        <h1>🎯 模型維度 (d_model) 演進史</h1>
        
        <div class="key-concept">
            <h3>✅ 你的理解完全正確！</h3>
            <p><strong>d_model = 每個 token 的向量維度</strong></p>
            <p>無論是「play」、「貓」、「的」,每個 token 都會被轉換成一個 <strong>d_model 維度的向量</strong>。</p>
        </div>

        <h2>🔢 什麼是 d_model?</h2>

        <div class="text-pair">
            <div class="original-text">
                <strong>定義:</strong> d_model (model dimension) is the dimensionality of the embedding vector that represents each token throughout the entire model.
            </div>
            <div class="translation">
                <strong>定義:</strong> d_model(模型維度)是代表每個 token 在整個模型中的嵌入向量的維度數。
            </div>
        </div>

        <div class="explanation">
            <h4>📝 實際範例</h4>
            
            <h5>Transformer (2017): d_model = 512</h5>
            <pre><code>輸入句子: "I love AI"
            
Token 化後:
- "I"    → [0.2, -0.5, 0.8, ..., 0.1]  (512 個數字)
- "love" → [0.7, 0.3, -0.2, ..., 0.9]  (512 個數字)
- "AI"   → [-0.1, 0.6, 0.4, ..., -0.3] (512 個數字)
            </code></pre>

            <h5>GPT-3 (2020): d_model = 12,288</h5>
            <pre><code>輸入句子: "I love AI"
            
Token 化後:
- "I"    → [0.2, -0.5, 0.8, ..., 0.1]  (12,288 個數字！)
- "love" → [0.7, 0.3, -0.2, ..., 0.9]  (12,288 個數字！)
- "AI"   → [-0.1, 0.6, 0.4, ..., -0.3] (12,288 個數字！)
            </code></pre>

            <p><strong>差異:</strong></p>
            <p>GPT-3 用 <strong>24 倍</strong>的維度來表示每個 token!</p>
            <p>維度越高 → 能編碼的資訊越豐富!</p>
        </div>

        <h2>📊 三大模型的維度對比</h2>

        <div class="comparison-grid">
            <div class="model-card">
                <h3>⚡ Transformer (2017)</h3>
                <p><strong>d_model = 512</strong></p>
                <div class="dimension-bar" style="width: 20%;">
                    <span class="dimension-label">512</span>
                </div>
                <ul>
                    <li>層數: 6 (Encoder) + 6 (Decoder)</li>
                    <li>注意力頭: 8</li>
                    <li>參數: ~65M</li>
                </ul>
                <p><strong>設計理念:</strong>平衡效能與效率</p>
            </div>

            <div class="model-card" style="border-top-color: var(--secondary-color);">
                <h3>🔄 BERT Base (2018)</h3>
                <p><strong>d_model = 768</strong></p>
                <div class="dimension-bar" style="width: 30%; background: linear-gradient(90deg, var(--secondary-color), var(--accent-color));">
                    <span class="dimension-label">768</span>
                </div>
                <ul>
                    <li>層數: 12 (Encoder only)</li>
                    <li>注意力頭: 12</li>
                    <li>參數: 110M</li>
                </ul>
                <p><strong>設計理念:</strong>增加表達能力</p>
            </div>

            <div class="model-card" style="border-top-color: var(--accent-color);">
                <h3>🔄 BERT Large (2018)</h3>
                <p><strong>d_model = 1024</strong></p>
                <div class="dimension-bar" style="width: 40%; background: linear-gradient(90deg, var(--accent-color), var(--purple-color));">
                    <span class="dimension-label">1024</span>
                </div>
                <ul>
                    <li>層數: 24</li>
                    <li>注意力頭: 16</li>
                    <li>參數: 340M</li>
                </ul>
                <p><strong>首次突破 1000 維！</strong></p>
            </div>

            <div class="model-card" style="border-top-color: var(--purple-color);">
                <h3>🌟 GPT-3 175B (2020)</h3>
                <p><strong>d_model = 12,288</strong></p>
                <div class="dimension-bar" style="width: 100%; background: linear-gradient(90deg, var(--purple-color), var(--danger-color));">
                    <span class="dimension-label">12,288</span>
                </div>
                <ul>
                    <li>層數: 96 (Decoder only)</li>
                    <li>注意力頭: 96</li>
                    <li>參數: 175B</li>
                </ul>
                <p><strong>設計理念:</strong>極致的表達能力!</p>
            </div>
        </div>

        <h2>🎨 視覺化:Token 向量的演進</h2>

        <div style="margin: 40px 0; text-align: center;">
            <img src="../images/user_generate_image_20260101095228_e775.png" 
                 alt="維度演進對比" 
                 style="max-width: 100%; border-radius: var(--radius-lg); box-shadow: var(--shadow-lg);">
            <p class="caption">
                <strong>📊 d_model 維度演進視覺化</strong><br>
                從下到上:Transformer (512維, 20%) → BERT (1024維, 40%) → GPT-3 (12,288維, 100%)<br>
                每個 token 的向量長度<strong>增長 24 倍</strong>,表達能力呈指數級提升！
            </p>
        </div>

        <div class="dimension-visual">
            <h4>Token "play" 的表示方式</h4>
            
            <div style="margin: 30px 0;">
                <h5>📦 Transformer (512 維)</h5>
                <div style="display: flex; flex-wrap: wrap; gap: 3px;">
                    <span style="font-size: 0.7rem; color: var(--primary-color);">[ 0.23, -0.51, 0.82, ..., 0.15 ]</span>
                    <span style="color: var(--text-secondary);">(512 個數字)</span>
                </div>
                <div style="height: 20px; background: var(--primary-color); width: 20%; margin: 10px 0; border-radius: 4px;"></div>
                <p style="font-size: 0.9rem; color: var(--text-secondary);">可以編碼基本語義、簡單的語法關係</p>
            </div>

            <div style="margin: 30px 0;">
                <h5>📦 BERT Large (1024 維)</h5>
                <div style="display: flex; flex-wrap: wrap; gap: 3px;">
                    <span style="font-size: 0.7rem; color: var(--secondary-color);">[ 0.23, -0.51, 0.82, ..., 0.15 ]</span>
                    <span style="color: var(--text-secondary);">(1024 個數字)</span>
                </div>
                <div style="height: 20px; background: var(--secondary-color); width: 40%; margin: 10px 0; border-radius: 4px;"></div>
                <p style="font-size: 0.9rem; color: var(--text-secondary);">可以編碼更豐富的語義、上下文依賴</p>
            </div>

            <div style="margin: 30px 0;">
                <h5>📦 GPT-3 (12,288 維)</h5>
                <div style="display: flex; flex-wrap: wrap; gap: 3px;">
                    <span style="font-size: 0.7rem; color: var(--purple-color);">[ 0.23, -0.51, 0.82, ..., 0.15 ]</span>
                    <span style="color: var(--text-secondary);">(12,288 個數字！)</span>
                </div>
                <div style="height: 20px; background: var(--purple-color); width: 100%; margin: 10px 0; border-radius: 4px;"></div>
                <p style="font-size: 0.9rem; color: var(--text-secondary);"><strong>可以編碼極其豐富的資訊:</strong>語義、語法、風格、語氣、隱含意義、文化背景...</p>
            </div>
        </div>

        <h2>💡 為什麼要增加維度?</h2>

        <div style="margin: 40px 0; text-align: center;">
            <img src="../images/user_generate_image_20260101095252_1a42.png" 
                 alt="維度類比:從2D到高維空間" 
                 style="max-width: 600px; width: 100%; border-radius: var(--radius-lg); box-shadow: var(--shadow-lg);">
            <p class="caption">
                <strong>🏙️ 維度容量的生活類比</strong><br>
                2D 平面 (紙張) → 3D 空間 (盒子) → 512D (房子) → 12,288D (城市)<br>
                維度越高 → 可容納的資訊越多 → AI 理解越深刻！
            </p>
        </div>

        <div class="analogy">
            <h4>🎨 生活類比:畫筆的精細度</h4>
            
            <p><strong>場景:畫一張臉</strong></p>
            
            <div style="margin: 20px 0;">
                <p><strong>512 維 = 12 色蠟筆</strong></p>
                <ul>
                    <li>只能畫出「笑臉」「哭臉」等基本表情</li>
                    <li>顏色選擇有限</li>
                    <li>細節不夠豐富</li>
                </ul>
            </div>

            <div style="margin: 20px 0;">
                <p><strong>1024 維 = 48 色彩色筆</strong></p>
                <ul>
                    <li>可以畫出更細膩的表情</li>
                    <li>有更多色彩層次</li>
                    <li>能表現光影變化</li>
                </ul>
            </div>

            <div style="margin: 20px 0;">
                <p><strong>12,288 維 = 專業油畫顏料</strong></p>
                <ul>
                    <li>可以畫出照片級細節</li>
                    <li>無限混色可能</li>
                    <li>能表現微妙的情感和氛圍</li>
                </ul>
            </div>
        </div>

        <div class="analogy">
            <h4>🤖 工程類比:記憶體容量</h4>
            
            <p>想像每個 token 是一個「檔案」:</p>
            
            <ul>
                <li><strong>512 維</strong> = 每個檔案 2KB → 只能儲存純文字</li>
                <li><strong>1024 維</strong> = 每個檔案 4KB → 可以加一些格式和註解</li>
                <li><strong>12,288 維</strong> = 每個檔案 48KB → 可以儲存文字+格式+關聯+上下文+語義層次</li>
            </ul>
        </div>

        <h2>📐 數學角度:維度與表達能力</h2>

        <div class="explanation">
            <h4>為什麼維度越高越好?</h4>
            
            <p><strong>直覺理解:</strong></p>
            <p>在 d 維空間中,你可以區分的「不同點」的數量大約是:</p>

            <p>\[ N \approx 2^d \]</p>

            <p><strong>實際比較:</strong></p>
            <ul>
                <li>512 維: 可以區分 \(2^{512}\) 個不同的概念</li>
                <li>12,288 維: 可以區分 \(2^{12288}\) 個不同的概念</li>
            </ul>

            <p>\(2^{12288} \gg 2^{512}\) (大得不可思議！)</p>

            <p><strong>更精確的說法:</strong></p>
            <p>維度越高 → 表達空間越大 → 能編碼的微妙差異越多!</p>
        </div>

        <h2>⚖️ 但維度不是越高越好！</h2>

        <div class="problem">
            <h4>❌ 維度過高的問題</h4>
            
            <table>
                <thead>
                    <tr>
                        <th>問題</th>
                        <th>說明</th>
                        <th>影響</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>計算成本</strong></td>
                        <td>參數量 ∝ d² (注意力矩陣)</td>
                        <td>512→12288 = <strong>576 倍</strong>計算量</td>
                    </tr>
                    <tr>
                        <td><strong>記憶體需求</strong></td>
                        <td>需要儲存更多參數</td>
                        <td>GPT-3 需要 350GB RAM (FP16)</td>
                    </tr>
                    <tr>
                        <td><strong>訓練時間</strong></td>
                        <td>更多參數 = 更慢收斂</td>
                        <td>GPT-3 訓練成本 $4.6M</td>
                    </tr>
                    <tr>
                        <td><strong>過擬合風險</strong></td>
                        <td>維度過高可能記住訓練資料</td>
                        <td>需要更多資料來平衡</td>
                    </tr>
                </tbody>
            </table>
        </div>

        <div class="key-concept">
            <h4>🎯 最佳維度選擇</h4>
            <p><strong>Scaling Law 的發現:</strong></p>
            <p>在給定計算預算下,最佳的策略是<strong>同時增加</strong>:</p>
            <ul>
                <li>模型大小 (d_model, 層數)</li>
                <li>資料量</li>
                <li>訓練時間</li>
            </ul>
            <p>比例大約是: 模型:資料:計算 ≈ 1:1:1</p>
        </div>

        <h2>🔗 維度與其他參數的關係</h2>

        <div class="explanation">
            <h4>d_model 如何影響其他設計</h4>
            
            <table>
                <thead>
                    <tr>
                        <th>參數</th>
                        <th>與 d_model 的關係</th>
                        <th>Transformer</th>
                        <th>GPT-3</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>d_model</strong></td>
                        <td>-</td>
                        <td>512</td>
                        <td>12,288</td>
                    </tr>
                    <tr>
                        <td><strong>n_heads</strong></td>
                        <td>通常 d_model / 64</td>
                        <td>8</td>
                        <td>96</td>
                    </tr>
                    <tr>
                        <td><strong>d_head</strong></td>
                        <td>d_model / n_heads</td>
                        <td>64</td>
                        <td>128</td>
                    </tr>
                    <tr>
                        <td><strong>d_ff</strong></td>
                        <td>通常 4 × d_model</td>
                        <td>2048</td>
                        <td>49,152</td>
                    </tr>
                </tbody>
            </table>

            <p><strong>關鍵發現:</strong></p>
            <p>當你增加 d_model,所有相關維度都會按比例增加!</p>
        </div>

        <h2>🎓 總結</h2>

        <div class="key-concept">
            <h4>✅ 核心要點</h4>
            
            <ol>
                <li>
                    <strong>d_model = 每個 token 的向量維度</strong>
                    <p>「play」從 512 維 → 12,288 維</p>
                </li>
                <li>
                    <strong>維度越高 = 表達能力越強</strong>
                    <p>能編碼更豐富、更細膩的語義資訊</p>
                </li>
                <li>
                    <strong>演進趨勢: 512 → 768 → 1024 → 12,288</strong>
                    <p>三年內成長了 <strong>24 倍</strong>!</p>
                </li>
                <li>
                    <strong>代價:計算成本指數級增長</strong>
                    <p>需要更多 GPU、更多電力、更多錢</p>
                </li>
                <li>
                    <strong>但值得!</strong>
                    <p>更大的維度 → 更聰明的模型 → ChatGPT 的誕生!</p>
                </li>
            </ol>
        </div>

        <div style="background: linear-gradient(135deg, var(--primary-light), var(--secondary-light)); padding: 30px; border-radius: var(--radius-lg); text-align: center; margin: 40px 0;">
            <h3>🚀 從 512 到 12,288 的旅程</h3>
            <p style="font-size: 1.2rem; line-height: 1.8;">
                這不只是數字的增長,<br>
                更是 AI 理解能力的<strong>質變</strong>!<br><br>
                從「看懂句子」→ 到「理解語境」→ 到「掌握微妙語氣」<br>
                這就是為什麼 GPT-3 感覺「像人」!
            </p>
        </div>

        <div class="quick-links">
            <a href="../index.html" class="quick-link">← 回到三部曲總覽</a>
            <a href="tokenizer-embedding-explained.html" class="quick-link">← 上一專題:Tokenizer</a>
            <a href="gpt3-96-layers-architecture.html" class="quick-link">下一專題 → 96層架構</a>
        </div>
        
        <div class="quick-links" style="margin-top: 20px;">
            <a href="../transformer-tutorial/index.html" class="quick-link">📖 Transformer 教學</a>
            <a href="../bert-tutorial/index.html" class="quick-link">📖 BERT 教學</a>
            <a href="../gpt3-tutorial/index.html" class="quick-link">📖 GPT-3 教學</a>
        </div>
    </div>
</body>
</html>

