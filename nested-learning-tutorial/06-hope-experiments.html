<!DOCTYPE html>
<html lang="zh-TW">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <!-- Primary Meta Tags -->
    <title>Hope 模型與實驗結果 - Nested Learning 論文導讀 | AI Paper Archaeology</title>
    <meta
      name="description"
      content="實戰驗證：Self-Modifying Titans 與 Hope 模型。在持續學習、長上下文理解與語言建模任務上的表現如何？深入解析 Hope 模型在 CLINC、Banking、DBpedia、BABILong 等基準測試中的優異表現。"
    />
    <meta
      name="keywords"
      content="Hope 模型, Self-Modifying Titans, 持續學習, Continual Learning, 長上下文理解, Long Context, BABILong, CLINC, 實驗結果, Nested Learning"
    />
    <meta name="author" content="謝承緯 (Chen Wei Hsieh)" />
    <meta name="robots" content="index, follow" />
    <link
      rel="canonical"
      href="https://hsiehchenwei.github.io/ai-paper-archaeology/nested-learning-tutorial/06-hope-experiments.html"
    />

    <!-- Open Graph / Facebook -->
    <meta property="og:type" content="article" />
    <meta
      property="og:url"
      content="https://hsiehchenwei.github.io/ai-paper-archaeology/nested-learning-tutorial/06-hope-experiments.html"
    />
    <meta
      property="og:title"
      content="Hope 模型與實驗結果 - Nested Learning 論文導讀"
    />
    <meta
      property="og:description"
      content="實戰驗證：Self-Modifying Titans 與 Hope 模型。在持續學習、長上下文理解與語言建模任務上的表現如何？"
    />
    <meta
      property="og:image"
      content="https://hsiehchenwei.github.io/ai-paper-archaeology/nested-learning-tutorial/images/generated/hero-06-hope.png"
    />
    <meta property="og:locale" content="zh_TW" />
    <meta property="og:site_name" content="AI Paper Archaeology" />

    <!-- Twitter -->
    <meta property="twitter:card" content="summary_large_image" />
    <meta
      property="twitter:url"
      content="https://hsiehchenwei.github.io/ai-paper-archaeology/nested-learning-tutorial/06-hope-experiments.html"
    />
    <meta
      property="twitter:title"
      content="Hope 模型與實驗結果 - Nested Learning 論文導讀"
    />
    <meta
      property="twitter:description"
      content="實戰驗證：Self-Modifying Titans 與 Hope 模型。在持續學習、長上下文理解與語言建模任務上的表現如何？"
    />
    <meta
      property="twitter:image"
      content="https://hsiehchenwei.github.io/ai-paper-archaeology/nested-learning-tutorial/images/generated/hero-06-hope.png"
    />

    <link rel="stylesheet" href="../styles/global.css">
    <link rel="stylesheet" href="../styles/paper-reading.css">
    <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+TC:wght@400;700&family=Inter:wght@400;600;700&display=swap" rel="stylesheet">
</head>
<body>
    <div class="container">
        <!-- Breadcrumb -->
        <div class="breadcrumb">
            <a href="../index.html">🏠 首頁</a>
            <span>/</span>
            <a href="index.html">🔗 Nested Learning</a>
            <span>/</span>
            <span class="current">06 Hope 模型與實驗結果</span>
        </div>

        <!-- Hero Section -->
        <div class="hero-section" style="background-image: url('images/generated/hero-06-hope.png');">
            <div class="hero-overlay"></div>
            <div class="hero-content">
                <h1>Hope：自我進化的希望</h1>
                <div class="hero-subtitle">當理論付諸實踐，我們得到了一個能自我修改的模型</div>
                <div class="hero-meta">Chapter 6 · 實證分析</div>
            </div>
        </div>

        <!-- Story Container -->
        <div class="story-container">
            <div class="story-lead">
                所有的理論都很美好，但它真的管用嗎？讓我們來看看 Hope (A Self-Referential Learning Module with Continuum Memory) 模型的實戰表現。
            </div>

            <p class="drop-cap">
                Hope 不僅僅是一個新模型，它是 Nested Learning 理念的集大成者。它結合了 Self-Modifying Titans（自我修改的泰坦）架構和 Continuum Memory System（連續體記憶系統），實現了「自我參照」的學習能力。
            </p>

            <p>
                最令人興奮的特性是：<strong>它學會了如何學習</strong>。它的內層優化器不僅僅是預先寫好的數學公式，而是一個可以被訓練、被修改的學習模組。
            </p>

            <div class="original-quote">
                "Our Hope architecture based on a self-modifying Titans and CMS improves continual learning and long-context reasoning capabilities, while remaining competitive as a general backbone."
                <br><br>
                <strong>📄 論文原文翻譯：</strong> 我們的 Hope 架構基於 Self-Modifying Titans 和 CMS，改進了持續學習和長上下文推理能力，同時作為通用骨幹網路仍保持競爭力。
            </div>

            <div class="section-divider"><span>✦</span></div>

            <h2>實驗 1：持續學習能力 (Continual Learning)</h2>

            <p>
                這是本次論文的重頭戲。在 Class-Incremental Learning 任務中，模型需要不斷學習新的類別，同時不忘記舊的類別。
            </p>

            <div class="myboxi" style="background: linear-gradient(135deg, #fff7ed 0%, #ffedd5 100%); border-color: #f97316;">
                <strong>📖 什麼是「災難性遺忘」(Catastrophic Forgetting)？</strong><br><br>
                
                想像你今天學了法文，明天學了德文。如果學完德文之後，你突然忘記了所有的法文，這就是<strong>災難性遺忘</strong>。<br><br>
                
                在神經網路中，當模型學習新任務時，為了儲存新知識而覆蓋了舊知識的神經元連接，導致在舊任務上的表現急劇下降。這是深度學習的一個經典難題。<br><br>
                
                <div class="original-quote" style="margin-top: 16px;">
                    "From nested learning viewpoint on learning and backpropagation process, catastrophic forgetting is a natural consequence of compression, where the limited capacity of the network forces the model to forget so that it retains capacity for new information."
                    <br><br>
                    <strong>📄 論文原文翻譯：</strong> 從巢狀學習對學習和反向傳播過程的觀點來看，災難性遺忘是壓縮的自然結果——網路的有限容量迫使模型遺忘舊知識，以便為新資訊保留空間。
                </div>
                <br>
                
                <strong>💡 為什麼會發生？</strong><br>
                傳統神經網路的所有參數都在同一個時間尺度上更新。當學習新任務時，梯度下降會調整權重以適應新數據，但這些調整往往會破壞之前學到的模式。就像在同一張紙上不斷擦掉舊字寫新字，最後什麼都看不清了。<br><br>
                
                <strong>🎯 Hope 如何解決？</strong><br>
                Hope 的多層級記憶設計（CMS）讓不同的記憶層以不同的頻率更新。當一個快速更新的層可能遺忘某些知識時，慢速更新的層仍然保留著這些知識，並且可以透過反向傳播將知識「傳回」給快速層。這形成了一個時間維度上的循環，讓重要知識難以被完全遺忘。
            </div>

            <div class="bento-grid">
                <div class="bento-card">
                    <img src="images/original/CLINC.png" alt="CLINC Results" style="width:100%">
                    <p style="text-align:center; font-size:0.9em; color:#666">CLINC (意圖分類)</p>
                </div>
                <div class="bento-card">
                    <img src="images/original/Banking.png" alt="Banking Results" style="width:100%">
                    <p style="text-align:center; font-size:0.9em; color:#666">Banking (銀行業務)</p>
                </div>
                <div class="bento-card">
                    <img src="images/original/DBpedia.png" alt="DBpedia Results" style="width:100%">
                    <p style="text-align:center; font-size:0.9em; color:#666">DBpedia (維基百科)</p>
                </div>
            </div>

            <div class="myboxi">
                <strong>📊 圖表解讀指南</strong><br><br>
                
                <strong>🎨 顏色系統：</strong><br>
                <ul style="margin-top: 8px; margin-bottom: 12px;">
                    <li><strong style="color: #ef4444;">紅色系（四種深淺）：</strong>Llama-3B 模型（3B 參數）的四種訓練方法</li>
                    <li style="margin-top: 6px;"><strong style="color: #3b82f6;">藍色系（四種深淺）：</strong>Llama3-8B 模型（8B 參數）的四種訓練方法</li>
                </ul>
                
                <strong>🔧 四種訓練方法（按顏色由淺到深）：</strong><br>
                <ul style="margin-top: 8px; margin-bottom: 12px;">
                    <li><strong>最淺色 - In-Context (ICL)：</strong>標準的 Llama-3，只靠上下文學習，不修改模型架構。</li>
                    <li style="margin-top: 6px;"><strong>中淺色 - EWC (Elastic Weight Consolidation)：</strong>傳統的持續學習方法，透過限制重要權重的變化來防止遺忘。</li>
                    <li style="margin-top: 6px;"><strong>中深色 - InCA (In-context Continual Learning with External Learner)：</strong>使用外部學習器的持續學習方法。</li>
                    <li style="margin-top: 6px;"><strong>最深色 - Hope（本研究）：</strong>把 Llama-3 的 MLP 層改造成「可適應的多層級記憶系統」（CMS），然後用 15B tokens 進行持續預訓練。</li>
                </ul>
                
                <strong>📈 關鍵發現：</strong>
                <ul style="margin-top: 8px; margin-bottom: 0;">
                    <li>在所有三個測試中，<strong style="color: #7c2d12;">最深色的柱子（Hope）</strong>都是最高的，無論是 3B 還是 8B 模型。</li>
                    <li style="margin-top: 6px;">這證明了<strong>同一個 Llama-3 基底模型</strong>，只要用對訓練方式（多層級記憶設計），就能顯著提升持續學習能力，有效抵抗災難性遺忘。</li>
                </ul>
            </div>

            <h2>實驗 2：長上下文理解 (Long Context)</h2>

            <p>
                如果模型記性好，那它能在像大海撈針一樣的任務中找到答案嗎？
            </p>

            <!-- Original Image: NIAH Levels -->
            <div class="figure figure-original">
                <img src="images/original/NIAH-levels.png" alt="Needle In A Haystack Results">
                <div class="caption">
                    <strong>🖼️ 論文原圖：</strong> 在「大海撈針」(Needle-in-a-Haystack) 測試中，隨著記憶層級（Level）的增加，Hope 的表現穩步提升。這驗證了 Nested Learning 的核心假設：更多的層級 = 更強的計算深度與記憶力。
                </div>
            </div>

            <p>
                而在更極端的 BABILong 測試（上下文長度達到 10M token）中，大多數模型（包括 GPT-4）在超過一定長度後表現都會崩潰。但 Hope 憑藉其 CMS 設計，成功維持了穩定的性能。
            </p>

            <!-- Original Image: BABILong -->
            <div class="figure figure-original">
                <img src="images/original/BABILong.png" alt="BABILong Results">
                <div class="caption">
                    <strong>🖼️ 論文原圖：</strong> BABILong 基準測試結果。當上下文長度超過 128K 時，大多數模型（包括 GPT-4）的性能都會急劇下降。但 Hope 能在 10M token 的極端長度下維持穩定表現，這歸功於其 CMS 設計。
                </div>
            </div>

            <h3>更多長上下文測試</h3>

            <div class="bento-grid">
                <div class="bento-card">
                    <img src="images/original/LongHelath-levels.png" alt="LongHealth Results" style="width:100%">
                    <p style="text-align:center; font-size:0.9em; color:#666">LongHealth (醫療問答)</p>
                </div>
                <div class="bento-card">
                    <img src="images/original/QASPER-levels.png" alt="QASPER Results" style="width:100%">
                    <p style="text-align:center; font-size:0.9em; color:#666">QASPER (論文問答)</p>
                </div>
            </div>

            <div class="myboxi">
                <strong>📊 解讀：</strong> 
                在 LongHealth（醫療問答）和 QASPER（論文問答）任務中，隨著記憶層級的增加，Hope 的表現持續提升。這證明了「更多層級 = 更強的長上下文理解能力」這一核心假設。
            </div>

            <h2>實驗 3：持續翻譯新語言 (Continual Translation)</h2>

            <p>
                這個實驗非常有趣——它讓 AI 模型像人類一樣「連續學習」兩種完全陌生的語言。
            </p>

            <p>
                想像你今天學了滿洲語，明天學了 Kalamang 語（一種印尼的稀有語言）。如果你學完 Kalamang 之後，突然忘記了所有的滿洲語，那就是「災難性遺忘」。
            </p>

            <h3>實驗設計：CTNL (Continual Translation of a Novel Language)</h3>

            <p>
                論文設計了一個新的基準測試，結合了兩個現有的稀有語言資料集（MTOB 和 Manchu），讓模型：
            </p>

            <ol>
                <li><strong>第一階段：</strong>先學習滿洲語 → 英文的翻譯</li>
                <li><strong>第二階段：</strong>再學習 Kalamang 語 → 英文的翻譯</li>
                <li><strong>測試：</strong>看看學完第二種語言後，是否還記得第一種語言</li>
            </ol>

            <div class="myboxi">
                <strong>🎯 兩種測試設定</strong><br><br>
                
                <strong style="color: #dc2626;">紅色點 - 「單獨學習」：</strong>模型分別學習兩種語言，沒有遺忘的問題。這是理想狀態的基準線。<br><br>
                
                <strong style="color: #2563eb;">藍色點 - 「連續學習」：</strong>模型先學滿洲語，再學 Kalamang 語。這會觸發災難性遺忘——學新的會忘記舊的。
            </div>

            <!-- Original Image: ICL Translate -->
            <div class="figure figure-original">
                <img src="images/original/ICL-Translate.png" alt="ICL Translation Results">
                <div class="caption">
                    <strong>🖼️ 論文原圖：</strong> 持續學習翻譯任務 (CTNL)。橫軸是滿洲語→英文的翻譯品質（ChRF 分數），縱軸是 Kalamang 語→英文的翻譯品質。每個點代表一個模型。紅點是「單獨學習」（理想狀態），藍點是「連續學習」（會遺忘）。
                </div>
            </div>

            <h3>結果解讀：記憶層級越多，遺忘越少</h3>

            <p>
                圖中有四個模型的對比：
            </p>

            <ul>
                <li><strong>ICL（標準 Llama-3）：</strong>藍點掉到左下角，幾乎完全忘記了滿洲語。這是典型的災難性遺忘。</li>
                <li><strong>Hope-1（1 層額外記憶）：</strong>稍微好一點，但還是有明顯遺忘。</li>
                <li><strong>Hope-2（2 層額外記憶）：</strong>表現更好，開始接近紅點。</li>
                <li><strong>Hope-3（3 層額外記憶）：</strong>藍點幾乎和紅點重疊！這代表即使連續學習兩種新語言，Hope-3 也幾乎不會遺忘第一種語言。</li>
            </ul>

            <div class="quote-block">
                「在第一種設定（單獨學習）中，所有 Hope 變體的表現都優於或持平於 ICL。但在第二種設定（連續學習）中，ICL 面臨劇烈的性能下降，幾乎只能依靠預訓練時的能力——這就是對上下文知識的災難性遺忘。相反，增加記憶層級的 Hope-3 幾乎完全恢復了第一種設定的能力。」
            </div>

            <p>
                這個實驗的意義在於：它直接驗證了論文的核心論點——<strong>更多的記憶層級 = 更強的持續學習能力</strong>。當模型有多個不同頻率的記憶層級時，它可以在學習新知識的同時，保留舊知識。
            </p>

            <h2>實驗 4：語言建模與常識推理 (Language Modeling & Common-Sense Reasoning)</h2>

            <p>
                前面的實驗展示了 Hope 在持續學習和長上下文任務上的「特技」。但一個模型要真正有用，基本功也要扎實。那麼，Hope 在最基礎的語言建模任務上表現如何？
            </p>

            <h3>實驗設定</h3>

            <p>
                論文使用了兩種規模的模型，從零開始訓練：
            </p>

            <div class="paradigm-grid">
                <div class="paradigm-card">
                    <h4>760M 參數模型</h4>
                    <p>用 30B tokens 訓練，來自 FineWeb-Edu 和長上下文文檔的混合數據集。</p>
                </div>
                <div class="paradigm-card">
                    <h4>1.3B 參數模型</h4>
                    <p>用 100B tokens 訓練，同樣的數據來源，但訓練規模更大。</p>
                </div>
            </div>

            <h3>評測基準</h3>

            <p>
                論文在兩大類任務上測試模型：
            </p>

            <div class="myboxi">
                <strong>📚 語言建模任務：</strong><br>
                <ul style="margin-top: 8px; margin-bottom: 12px;">
                    <li><strong>WikiText：</strong>測試模型對維基百科文本的理解和預測能力（Perplexity 越低越好）</li>
                    <li><strong>LAMBADA (LMB)：</strong>測試長距離依賴理解，需要根據長上下文預測最後一個詞</li>
                </ul>
                
                <strong>🧠 常識推理任務：</strong><br>
                <ul style="margin-top: 8px; margin-bottom: 0;">
                    <li><strong>PIQA：</strong>物理常識問答（如「如何讓鞋子防滑？」）</li>
                    <li><strong>HellaSwag：</strong>情境延續判斷（給定情境，選擇最合理的後續）</li>
                    <li><strong>WinoGrande：</strong>代詞消歧（考驗對句子結構和常識的理解）</li>
                    <li><strong>ARC-easy & ARC-challenge：</strong>科學問題（從簡單到困難）</li>
                    <li><strong>SIQA：</strong>社交情境推理</li>
                    <li><strong>BoolQ：</strong>是非題問答</li>
                </ul>
            </div>

            <h3>對手陣容：三大類基線模型</h3>

            <p>
                論文對比了非常全面的基線模型：
            </p>

            <ol>
                <li><strong>Transformer 系列：</strong>標準 Transformer 和 Samba（Attention + 線性 RNN 的混合體）</li>
                <li><strong>線性 RNN：</strong>RetNet、DeltaNet、RWKV-7、Comba（基於 Hebbian 或 Delta 規則的現代遞迴模型）</li>
                <li><strong>深度記憶模組：</strong>TTT、Miras、DLA、Titans（無 Attention 的深度記憶架構）</li>
            </ol>

            <h3>實驗結果：Hope 全面領先</h3>

            <div class="myboxi">
                <strong>🏆 760M 模型（30B tokens 訓練）</strong><br><br>
                
                <strong>語言建模：</strong><br>
                • WikiText Perplexity: <strong>18.68</strong>（Hope）vs 20.08（Titans，次佳）vs 24.18（Transformer）<br>
                • LAMBADA Perplexity: <strong>20.07</strong>（Hope）vs 21.52（Titans）vs 24.27（Transformer）<br><br>
                
                <strong>常識推理平均：</strong><br>
                • Hope: <strong>52.28%</strong><br>
                • Titans: 51.68%<br>
                • Samba (混合架構): 51.46%<br>
                • Transformer: 50.11%<br><br>
                
                <hr style="margin: 16px 0; border: none; border-top: 1px solid rgba(0,0,0,0.1);">
                
                <strong>🏆 1.3B 模型（100B tokens 訓練）</strong><br><br>
                
                <strong>語言建模：</strong><br>
                • WikiText Perplexity: <strong>14.39</strong>（Hope）vs 15.60（Titans）vs 17.92（Transformer）<br>
                • LAMBADA Perplexity: <strong>10.08</strong>（Hope）vs 11.41（Titans）vs 17.73（Transformer）<br><br>
                
                <strong>常識推理平均：</strong><br>
                • Hope: <strong>58.04%</strong><br>
                • Titans: 56.82%<br>
                • TTT: 55.58%<br>
                • Samba: 54.46%<br>
                • Transformer: 53.38%
            </div>

            <h3>關鍵發現</h3>

            <p>
                論文指出了一個重要趨勢：<strong>「隨著參數規模擴大，Hope 的性能增益比其他無 Attention 模型更明顯。」</strong>
            </p>

            <p>
                在 760M 模型中，Hope 比 Titans 只領先約 0.6%。但在 1.3B 模型中，這個差距擴大到 1.22%。這暗示了 Hope 的架構設計（多層級記憶 + 自我修改）在更大規模下會有更好的擴展性。
            </p>

            <div class="quote-block">
                「Hope 在語言建模和常識推理基準上的平均表現超越了所有基線模型。有趣的是，隨著參數的擴展，Hope 相比其他無 Attention 模型展現出更高的性能增益。」
            </div>

            <p>
                這個實驗的意義在於：<strong>Hope 不僅是為了解決特殊問題（持續學習、長上下文）而設計的專用架構，它本身就是一個高效的通用語言模型骨幹。</strong>它不僅擊敗了同量級的 Transformer，甚至在參數效率上超越了許多現代的線性 RNN 模型（如 Mamba、RWKV）。
            </p>

            <div class="section-divider"><span>✦</span></div>

            <h2>結語：未來的路</h2>

            <p>
                Nested Learning 告訴我們，深度學習的未來可能不在於堆疊更多的靜態層，而在於設計更豐富的<strong>動態層級</strong>。
            </p>
            
            <p>
                從大腦的神經振盪到 Git 的分支管理，從優化器的記憶到模型的自我進化，這一切都指向同一個方向：<strong>學習是一個巢狀的過程</strong>。
            </p>

            <div class="original-quote">
                "While Hope and CMS have shown promising results in reducing catastrophic forgetting in the tasks we empirically studied, the undesirable phenomenon of catastrophic forgetting is not 'solved' in general. We view NL as a roadmap rather than a destination: it suggests that progress on continual learning, long-context reasoning, modern optimizers, and self-modifying models will come from better exploiting the extra design axis of 'levels' rather than from ever-deeper static networks."
                <br><br>
                <strong>📄 論文原文翻譯：</strong> 雖然 Hope 和 CMS 在我們實證研究的任務中顯示出減少災難性遺忘的可喜成果，但這一不良現象並沒有被「徹底解決」。我們將 NL 視為一張路線圖，而非終點：它暗示持續學習、長上下文推理、現代優化器和自我修改模型的進展，將來自於更好地利用「層級」這一額外設計軸，而非更深的靜態網路。
            </div>

            <div class="quote-block">
                「災難性遺忘並沒有被徹底解決，但我們找到了一張地圖。這張地圖告訴我們：向『內』看，去探索層級的深度，而不僅僅是網路的深度。」
            </div>

            <p style="text-align: center; margin-top: 60px;">
                <a href="https://arxiv.org/abs/2512.24695" target="_blank" class="btn-primary" style="background: var(--mag-primary); color: white; padding: 15px 30px; border-radius: 99px; text-decoration: none; font-weight: bold; box-shadow: 0 4px 15px rgba(59, 130, 246, 0.4);">閱讀完整論文</a>
            </p>

            <!-- Navigation -->
            <div class="chapter-navigation">
                <a href="05-continuum-memory.html" class="nav-button">⬅️ 上一章：連續體記憶系統</a>
                <a href="index.html" class="nav-link">🏠 返回目錄</a>
            </div>
        </div>
    </div>
</body>
</html>