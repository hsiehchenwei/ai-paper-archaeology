<!DOCTYPE html>
<html lang="zh-TW">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>RAG åŸå§‹è«–æ–‡ï¼šæª¢ç´¢å¢å¼·ç”Ÿæˆçš„èª•ç”Ÿ | RAG æ¼”é€²å²</title>
    <meta name="description" content="Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks æ·±åº¦è§£æã€‚Patrick Lewis ç­‰äººæ­£å¼å®šç¾© RAG æ¶æ§‹ï¼ŒDPR + BART ç¶“å…¸çµ„åˆã€‚" />
    <link rel="stylesheet" href="../styles/global.css" />
    <link rel="stylesheet" href="../styles/paper-reading.css" />
    <link rel="stylesheet" href="../styles/articles.css" />
  </head>
  <body>
    <div class="container">
      <!-- éºµåŒ…å±‘å°èˆª -->
      <div class="breadcrumb">
        <a href="../index.html">ğŸ  é¦–é </a> / 
        <a href="index.html">ğŸ“š RAG æ¼”é€²å²</a> / 
        RAG åŸå§‹è«–æ–‡
      </div>

      <!-- è«–æ–‡è³‡è¨Šå¡ -->
      <div class="index-header" style="background: linear-gradient(135deg, var(--secondary-color), var(--primary-color));">
        <h1>â­ RAG åŸå§‹è«–æ–‡</h1>
        <p>Retrieval-Augmented Generation for<br />Knowledge-Intensive NLP Tasks</p>
        <p style="font-size: 0.9rem; margin-top: 15px; opacity: 0.95;">
          Patrick Lewis, Ethan Perez, Aleksandra Piktus, et al.<br />
          <strong>Facebook AI Research (Meta)</strong> Â· 2020 å¹´ 5 æœˆ
        </p>
        <p style="background: rgba(255,255,255,0.2); padding: 8px 16px; border-radius: 20px; margin-top: 15px; font-size: 0.9rem;">
          ğŸ† å®šç¾©ã€ŒRAGã€åç¨±èˆ‡æ¶æ§‹çš„ç¶“å…¸è«–æ–‡
        </p>
      </div>

      <!-- ä¸€å¥è©±ç¸½çµ -->
      <div class="key-concept">
        <h4>ğŸ’¡ ä¸€å¥è©±ç¸½çµ</h4>
        <p style="font-size: 1.1rem;">
          RAG å°‡ <strong>Dense Passage Retrieval (DPR)</strong> æª¢ç´¢å™¨èˆ‡ <strong>BART</strong> ç”Ÿæˆå™¨çµåˆï¼Œ
          å‰µé€ å‡ºæ—¢èƒ½ã€ŒæŸ¥è³‡æ–™ã€åˆèƒ½ã€Œå¯«ç­”æ¡ˆã€çš„å¼·å¤§æ¨¡å‹ï¼Œæˆç‚ºæ‰€æœ‰å¾ŒçºŒ RAG ç³»çµ±çš„åŸºç¤æ¶æ§‹ã€‚
        </p>
      </div>

      <!-- è«–æ–‡ PDF é€£çµ -->
      <div style="background: var(--primary-light); padding: 15px; border-radius: var(--radius-md); margin: 30px 0; text-align: center;">
        <a href="papers/rag.pdf" target="_blank" style="color: var(--primary-color); font-weight: 600; text-decoration: none; font-size: 1.05rem;">
          ğŸ“„ ä¸‹è¼‰è«–æ–‡åŸæ–‡ PDF â†’
        </a>
      </div>

      <!-- Abstract æ‘˜è¦ -->
      <h2>ğŸ“„ Abstract (æ‘˜è¦)</h2>

      <div class="original-quote">
        <strong>ğŸ“„ è«–æ–‡åŸæ–‡</strong><br><br>
        "Large pre-trained language models have been shown to store factual knowledge in their parameters, and achieve state-of-the-art results when fine-tuned on downstream NLP tasks. However, their ability to access and precisely manipulate knowledge is still limited, and hence on knowledge-intensive tasks, their performance lags behind task-specific architectures. Additionally, providing provenance for their decisions and updating their world knowledge remain open research problems."
        <br><br>
        <strong>ç¿»è­¯</strong>ï¼šå¤§å‹é è¨“ç·´èªè¨€æ¨¡å‹å·²è¢«è­‰æ˜èƒ½åœ¨åƒæ•¸ä¸­å„²å­˜äº‹å¯¦çŸ¥è­˜ï¼Œä¸¦åœ¨é‡å°ä¸‹æ¸¸ NLP ä»»å‹™é€²è¡Œå¾®èª¿æ™‚é”åˆ°æœ€å…ˆé€²çš„çµæœã€‚ç„¶è€Œï¼Œå®ƒå€‘å­˜å–å’Œç²¾ç¢ºæ“ä½œçŸ¥è­˜çš„èƒ½åŠ›ä»ç„¶æœ‰é™ï¼Œå› æ­¤åœ¨çŸ¥è­˜å¯†é›†å‹ä»»å‹™ä¸Šï¼Œå…¶è¡¨ç¾è½å¾Œæ–¼ç‰¹å®šä»»å‹™çš„æ¶æ§‹ã€‚æ­¤å¤–ï¼Œç‚ºå…¶æ±ºç­–æä¾›ä¾†æºè­‰æ˜å’Œæ›´æ–°å…¶ä¸–ç•ŒçŸ¥è­˜ä»ç„¶æ˜¯é–‹æ”¾çš„ç ”ç©¶å•é¡Œã€‚
      </div>

      <div class="explanation">
        <h4>ğŸ” æ ¸å¿ƒå•é¡Œ</h4>
        <p>è«–æ–‡é–‹é ­å°±é»å‡ºäº†å‚³çµ± LLM çš„ä¸‰å€‹æ ¹æœ¬å•é¡Œï¼š</p>
        <ul>
          <li><strong>çŸ¥è­˜å­˜å–å—é™</strong>ï¼šçŸ¥è­˜ã€Œé–ã€åœ¨åƒæ•¸è£¡ï¼Œé›£ä»¥ç²¾ç¢ºæå–</li>
          <li><strong>çŸ¥è­˜å¯†é›†å‹ä»»å‹™è¡¨ç¾ä¸ä½³</strong>ï¼šéœ€è¦å¤§é‡äº‹å¯¦çš„ä»»å‹™ï¼ˆå¦‚å•ç­”ï¼‰è¡¨ç¾ä¸å¦‚å°ˆé–€æ¶æ§‹</li>
          <li><strong>ç„¡æ³•è¿½æº¯ä¾†æº</strong>ï¼šä¸çŸ¥é“ç­”æ¡ˆå¾å“ªè£¡ä¾†</li>
          <li><strong>çŸ¥è­˜éæ™‚</strong>ï¼šç„¡æ³•æ›´æ–°ä¸–ç•ŒçŸ¥è­˜</li>
        </ul>
      </div>

      <div class="original-quote">
        <strong>ğŸ“„ è«–æ–‡åŸæ–‡ï¼ˆè§£æ±ºæ–¹æ¡ˆï¼‰</strong><br><br>
        "Pre-trained models with a differentiable access mechanism to explicit non-parametric memory can overcome this issue, but have so far been only investigated for extractive downstream tasks. We explore a general-purpose fine-tuning recipe for retrieval-augmented generation (RAG) -- models which combine pre-trained parametric and non-parametric memory for language generation."
        <br><br>
        <strong>ç¿»è­¯</strong>ï¼šå…·æœ‰å¯å¾®åˆ†å­˜å–æ©Ÿåˆ¶ä»¥å­˜å–æ˜ç¢ºéåƒæ•¸è¨˜æ†¶çš„é è¨“ç·´æ¨¡å‹å¯ä»¥å…‹æœé€™å€‹å•é¡Œï¼Œä½†è¿„ä»Šç‚ºæ­¢åƒ…åœ¨æŠ½å–å¼ä¸‹æ¸¸ä»»å‹™ä¸­é€²è¡Œäº†ç ”ç©¶ã€‚æˆ‘å€‘æ¢ç´¢äº†æª¢ç´¢å¢å¼·ç”Ÿæˆï¼ˆRAGï¼‰çš„é€šç”¨å¾®èª¿æ–¹æ³•â€”â€”çµåˆé è¨“ç·´åƒæ•¸è¨˜æ†¶å’Œéåƒæ•¸è¨˜æ†¶ç”¨æ–¼èªè¨€ç”Ÿæˆçš„æ¨¡å‹ã€‚
      </div>

      <div class="key-concept">
        <h4>ğŸ’¡ é—œéµæ¦‚å¿µï¼šåƒæ•¸è¨˜æ†¶ vs éåƒæ•¸è¨˜æ†¶</h4>
        <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); gap: 20px; margin-top: 20px;">
          <div style="background: white; padding: 20px; border-radius: var(--radius-md); border-left: 4px solid var(--primary-color);">
            <h5 style="color: var(--primary-color); margin-top: 0;">Parametric Memory<br />(åƒæ•¸è¨˜æ†¶)</h5>
            <p style="font-size: 0.95rem; line-height: 1.7;">
              çŸ¥è­˜å„²å­˜åœ¨æ¨¡å‹çš„<strong>åƒæ•¸</strong>ä¸­<br />
              ä¾‹å¦‚ï¼šGPT-3 çš„ 175B åƒæ•¸
            </p>
            <p style="font-size: 0.85rem; color: var(--text-secondary); margin-top: 10px;">
              âŒ é›£ä»¥æ›´æ–°<br />
              âŒ ç„¡æ³•è¿½æº¯ä¾†æº
            </p>
          </div>
          <div style="background: white; padding: 20px; border-radius: var(--radius-md); border-left: 4px solid var(--secondary-color);">
            <h5 style="color: var(--secondary-color); margin-top: 0;">Non-Parametric Memory<br />(éåƒæ•¸è¨˜æ†¶)</h5>
            <p style="font-size: 0.95rem; line-height: 1.7;">
              çŸ¥è­˜å„²å­˜åœ¨<strong>å¤–éƒ¨è³‡æ–™åº«</strong>ä¸­<br />
              ä¾‹å¦‚ï¼šWikipedia å‘é‡ç´¢å¼•
            </p>
            <p style="font-size: 0.85rem; color: var(--text-secondary); margin-top: 10px;">
              âœ… æ˜“æ–¼æ›´æ–°<br />
              âœ… å¯è¿½æº¯ä¾†æº
            </p>
          </div>
        </div>
        <p style="margin-top: 20px; font-weight: 600; color: var(--secondary-color);">
          RAG çš„å‰µæ–°ï¼š<strong>åŒæ™‚ä½¿ç”¨å…©ç¨®è¨˜æ†¶</strong>ï¼åƒæ•¸è¨˜æ†¶æä¾›èªè¨€èƒ½åŠ›ï¼Œéåƒæ•¸è¨˜æ†¶æä¾›äº‹å¯¦çŸ¥è­˜ã€‚
        </p>
      </div>

      <div class="original-quote">
        <strong>ğŸ“„ è«–æ–‡åŸæ–‡ï¼ˆæ ¸å¿ƒè²¢ç»ï¼‰</strong><br><br>
        "We introduce RAG models where the parametric memory is a pre-trained seq2seq model and the non-parametric memory is a dense vector index of Wikipedia, accessed with a pre-trained neural retriever. We compare two RAG formulations, one which conditions on the same retrieved passages across the whole generated sequence, the other can use different passages per token."
        <br><br>
        <strong>ç¿»è­¯</strong>ï¼šæˆ‘å€‘å¼•å…¥äº† RAG æ¨¡å‹ï¼Œå…¶ä¸­åƒæ•¸è¨˜æ†¶æ˜¯é è¨“ç·´çš„ seq2seq æ¨¡å‹ï¼Œéåƒæ•¸è¨˜æ†¶æ˜¯ Wikipedia çš„å¯†é›†å‘é‡ç´¢å¼•ï¼Œé€éé è¨“ç·´çš„ç¥ç¶“æª¢ç´¢å™¨å­˜å–ã€‚æˆ‘å€‘æ¯”è¼ƒäº†å…©ç¨® RAG å…¬å¼ï¼Œä¸€ç¨®åœ¨æ•´å€‹ç”Ÿæˆåºåˆ—ä¸­å°ç›¸åŒçš„æª¢ç´¢æ®µè½é€²è¡Œæ¢ä»¶åŒ–ï¼Œå¦ä¸€ç¨®å¯ä»¥åœ¨æ¯å€‹ token ä½¿ç”¨ä¸åŒçš„æ®µè½ã€‚
      </div>

      <!-- Introduction -->
      <h2>ğŸ“– Introduction (å¼•è¨€)</h2>

      <div class="original-quote">
        <strong>ğŸ“„ è«–æ–‡åŸæ–‡</strong><br><br>
        "Large pre-trained language models have been shown to store factual knowledge in their parameters, and achieve state-of-the-art results when fine-tuned on downstream NLP tasks. However, their ability to access and precisely manipulate knowledge is still limited, and hence on knowledge-intensive tasks, their performance lags behind task-specific architectures."
        <br><br>
        <strong>ç¿»è­¯</strong>ï¼šå¤§å‹é è¨“ç·´èªè¨€æ¨¡å‹å·²è¢«è­‰æ˜èƒ½åœ¨åƒæ•¸ä¸­å„²å­˜äº‹å¯¦çŸ¥è­˜ï¼Œä¸¦åœ¨é‡å°ä¸‹æ¸¸ NLP ä»»å‹™é€²è¡Œå¾®èª¿æ™‚é”åˆ°æœ€å…ˆé€²çš„çµæœã€‚ç„¶è€Œï¼Œå®ƒå€‘å­˜å–å’Œç²¾ç¢ºæ“ä½œçŸ¥è­˜çš„èƒ½åŠ›ä»ç„¶æœ‰é™ï¼Œå› æ­¤åœ¨çŸ¥è­˜å¯†é›†å‹ä»»å‹™ä¸Šï¼Œå…¶è¡¨ç¾è½å¾Œæ–¼ç‰¹å®šä»»å‹™çš„æ¶æ§‹ã€‚
      </div>

      <div class="explanation">
        <h4>ğŸ“œ ç‚ºä»€éº¼é€™ç¯‡æœ€é‡è¦ï¼Ÿ</h4>
        <ul>
          <li>æ­£å¼æå‡º <strong>"Retrieval-Augmented Generation"</strong> é€™å€‹åç¨±</li>
          <li>å»ºç«‹äº† <strong>Retriever + Generator</strong> çš„ç¶“å…¸æ¶æ§‹</li>
          <li>è­‰æ˜äº†ç«¯åˆ°ç«¯è¨“ç·´æª¢ç´¢å¢å¼·æ¨¡å‹çš„å¯è¡Œæ€§</li>
          <li>åœ¨å¤šå€‹çŸ¥è­˜å¯†é›†å‹ä»»å‹™ä¸Šå–å¾— SOTA</li>
          <li>è¢«å¾ŒçºŒå¹¾ä¹æ‰€æœ‰ RAG ç›¸é—œç ”ç©¶å¼•ç”¨</li>
        </ul>
        <p style="margin-top: 15px; font-weight: 600; color: var(--secondary-color);">
          é€™ç¯‡è«–æ–‡å®šç¾©äº†ä¸€å€‹æ–°çš„ç¯„å¼ï¼Œä»Šå¤©ä½ ç”¨çš„ä»»ä½• RAG ç³»çµ±ï¼Œéƒ½å¯ä»¥è¿½æº¯åˆ°é€™è£¡ï¼
        </p>
      </div>

      <div class="original-quote">
        <strong>ğŸ“„ è«–æ–‡åŸæ–‡ï¼ˆRAG çš„å„ªå‹¢ï¼‰</strong><br><br>
        "RAG models combine the benefits of parametric and non-parametric memory. The parametric memory (a pre-trained seq2seq model) provides the ability to generate fluent text, while the non-parametric memory (a dense vector index of Wikipedia) provides access to a large corpus of knowledge. This combination allows RAG models to generate text that is both fluent and factually accurate."
        <br><br>
        <strong>ç¿»è­¯</strong>ï¼šRAG æ¨¡å‹çµåˆäº†åƒæ•¸è¨˜æ†¶å’Œéåƒæ•¸è¨˜æ†¶çš„å„ªå‹¢ã€‚åƒæ•¸è¨˜æ†¶ï¼ˆé è¨“ç·´çš„ seq2seq æ¨¡å‹ï¼‰æä¾›äº†ç”Ÿæˆæµæš¢æ–‡æœ¬çš„èƒ½åŠ›ï¼Œè€Œéåƒæ•¸è¨˜æ†¶ï¼ˆWikipedia çš„å¯†é›†å‘é‡ç´¢å¼•ï¼‰æä¾›äº†å­˜å–å¤§å‹çŸ¥è­˜åº«çš„èƒ½åŠ›ã€‚é€™ç¨®çµåˆä½¿ RAG æ¨¡å‹èƒ½å¤ ç”Ÿæˆæ—¢æµæš¢åˆäº‹å¯¦æº–ç¢ºçš„æ–‡æœ¬ã€‚
      </div>

      <!-- æ ¸å¿ƒæ¶æ§‹ -->
      <h2>ğŸ”§ Method (æ–¹æ³•)</h2>

      <!-- è¦–è¦ºåŒ–åœ–è§£ -->
      <div style="text-align: center; margin: 40px 0;">
        <img src="images/rag-architecture.png" alt="RAG æ¶æ§‹åœ–ï¼šDPR + BART" style="max-width: 100%; border-radius: 12px; box-shadow: var(--shadow-lg);" />
        <p style="margin-top: 15px; color: var(--text-secondary); font-size: 0.9rem;">
          ğŸ“Š RAG ç¶“å…¸æ¶æ§‹ï¼šDense Passage Retrieval + BART Generator
        </p>
      </div>

      <div class="key-concept">
        <h4>ğŸ’¡ è«–æ–‡åŸå§‹åœ–è¡¨</h4>
        <p>
          RAG è«–æ–‡ä¸­çš„ <strong>Figure 1</strong> å±•ç¤ºäº†å®Œæ•´çš„ RAG æ¶æ§‹ï¼ŒåŒ…å«ï¼š
        </p>
        <ul>
          <li><strong>Query Encoder q(x)</strong>ï¼šå°‡è¼¸å…¥å•é¡Œç·¨ç¢¼ç‚ºå‘é‡</li>
          <li><strong>Document Index p(z|x)</strong>ï¼šä½¿ç”¨ DPR å¾ Wikipedia æª¢ç´¢ç›¸é—œæ–‡æª”</li>
          <li><strong>Generator p(y|x,z)</strong>ï¼šBART æ¨¡å‹æ ¹æ“šå•é¡Œå’Œæ–‡æª”ç”Ÿæˆç­”æ¡ˆ</li>
          <li><strong>Marginalization</strong>ï¼šå°å¤šå€‹æª¢ç´¢æ–‡æª”é€²è¡ŒåŠ æ¬Šæ•´åˆ</li>
        </ul>
        <p style="margin-top: 10px; font-size: 0.9rem; color: var(--text-secondary);">
          ğŸ“„ è«‹åƒè€ƒ <a href="papers/rag.pdf" target="_blank" style="color: var(--primary-color);">è«–æ–‡ PDF</a> ç¬¬ 3 é  Figure 1
        </p>
      </div>

      <div class="original-quote">
        <strong>ğŸ“„ è«–æ–‡åŸæ–‡ï¼ˆæ¶æ§‹æ¦‚è¿°ï¼‰</strong><br><br>
        "A RAG model consists of a question encoder (a query encoder), a document encoder (a passage encoder), and a generator. The question encoder and document encoder are both based on BERT, and are used to encode questions and documents into dense vectors. The generator is a pre-trained seq2seq model (BART) that generates answers conditioned on the retrieved documents."
        <br><br>
        <strong>ç¿»è­¯</strong>ï¼šRAG æ¨¡å‹ç”±å•é¡Œç·¨ç¢¼å™¨ï¼ˆæŸ¥è©¢ç·¨ç¢¼å™¨ï¼‰ã€æ–‡æª”ç·¨ç¢¼å™¨ï¼ˆæ®µè½ç·¨ç¢¼å™¨ï¼‰å’Œç”Ÿæˆå™¨çµ„æˆã€‚å•é¡Œç·¨ç¢¼å™¨å’Œæ–‡æª”ç·¨ç¢¼å™¨éƒ½åŸºæ–¼ BERTï¼Œç”¨æ–¼å°‡å•é¡Œå’Œæ–‡æª”ç·¨ç¢¼æˆå¯†é›†å‘é‡ã€‚ç”Ÿæˆå™¨æ˜¯é è¨“ç·´çš„ seq2seq æ¨¡å‹ï¼ˆBARTï¼‰ï¼Œæ ¹æ“šæª¢ç´¢åˆ°çš„æ–‡æª”ç”Ÿæˆç­”æ¡ˆã€‚
      </div>

      <div class="section-block">
        <h3 style="color: var(--primary-color);">RAG çš„å…©å¤§æ ¸å¿ƒçµ„ä»¶</h3>
        
        <div style="background: var(--primary-light); padding: 20px; border-radius: var(--radius-md); margin: 20px 0;">
          <h4 style="margin-top: 0;">ğŸ” Retrieverï¼šDPR (Dense Passage Retrieval)</h4>
          <ul>
            <li>ä½¿ç”¨ BERT å°‡æŸ¥è©¢å’Œæ–‡æª”ç·¨ç¢¼æˆå‘é‡</li>
            <li>é€éå‘é‡ç›¸ä¼¼åº¦æ‰¾åˆ°æœ€ç›¸é—œçš„ k å€‹æ–‡æª”</li>
            <li>é è¨“ç·´æ–¼ Natural Questions è³‡æ–™é›†</li>
            <li>æª¢ç´¢è³‡æ–™åº«ï¼šWikipedia (21M æ–‡æª”)</li>
          </ul>
        </div>

        <div class="original-quote" style="margin: 20px 0;">
          <strong>ğŸ“„ è«–æ–‡åŸæ–‡ï¼ˆDPR è©³è§£ï¼‰</strong><br><br>
          "We use Dense Passage Retrieval (DPR), which encodes queries and passages using two separate BERT encoders. The query encoder encodes the input question into a dense vector, and the passage encoder encodes each passage in the knowledge base into a dense vector. The top-k most similar passages are retrieved using maximum inner product search (MIPS)."
          <br><br>
          <strong>ç¿»è­¯</strong>ï¼šæˆ‘å€‘ä½¿ç”¨å¯†é›†æ®µè½æª¢ç´¢ï¼ˆDPRï¼‰ï¼Œå®ƒä½¿ç”¨å…©å€‹ç¨ç«‹çš„ BERT ç·¨ç¢¼å™¨ä¾†ç·¨ç¢¼æŸ¥è©¢å’Œæ®µè½ã€‚æŸ¥è©¢ç·¨ç¢¼å™¨å°‡è¼¸å…¥å•é¡Œç·¨ç¢¼æˆå¯†é›†å‘é‡ï¼Œæ®µè½ç·¨ç¢¼å™¨å°‡çŸ¥è­˜åº«ä¸­çš„æ¯å€‹æ®µè½ç·¨ç¢¼æˆå¯†é›†å‘é‡ã€‚ä½¿ç”¨æœ€å¤§å…§ç©æœå°‹ï¼ˆMIPSï¼‰æª¢ç´¢æœ€ç›¸ä¼¼çš„ top-k æ®µè½ã€‚
        </div>

        <div style="background: var(--secondary-light); padding: 20px; border-radius: var(--radius-md); margin: 20px 0;">
          <h4 style="margin-top: 0;">ğŸ“ Generatorï¼šBART</h4>
          <ul>
            <li>Sequence-to-Sequence æ¶æ§‹</li>
            <li>å¯ä»¥ç”Ÿæˆä»»æ„é•·åº¦çš„å›ç­”</li>
            <li>è¼¸å…¥ = æŸ¥è©¢ + æª¢ç´¢åˆ°çš„æ–‡æª”</li>
            <li>è¼¸å‡º = åŸºæ–¼è­‰æ“šçš„ç­”æ¡ˆ</li>
          </ul>
        </div>

        <div class="original-quote" style="margin: 20px 0;">
          <strong>ğŸ“„ è«–æ–‡åŸæ–‡ï¼ˆGenerator è©³è§£ï¼‰</strong><br><br>
          "The generator is a pre-trained BART model, which is a denoising autoencoder for pretraining sequence-to-sequence models. BART is particularly well-suited for conditional generation tasks, as it was trained to reconstruct text from corrupted versions, making it effective at generating coherent text from retrieved context."
          <br><br>
          <strong>ç¿»è­¯</strong>ï¼šç”Ÿæˆå™¨æ˜¯é è¨“ç·´çš„ BART æ¨¡å‹ï¼Œé€™æ˜¯ä¸€å€‹ç”¨æ–¼é è¨“ç·´åºåˆ—åˆ°åºåˆ—æ¨¡å‹çš„å»å™ªè‡ªç·¨ç¢¼å™¨ã€‚BART ç‰¹åˆ¥é©åˆæ¢ä»¶ç”Ÿæˆä»»å‹™ï¼Œå› ç‚ºå®ƒè¢«è¨“ç·´å¾æå£ç‰ˆæœ¬é‡å»ºæ–‡æœ¬ï¼Œä½¿å…¶èƒ½å¤ æœ‰æ•ˆåœ°å¾æª¢ç´¢åˆ°çš„ä¸Šä¸‹æ–‡ä¸­ç”Ÿæˆé€£è²«çš„æ–‡æœ¬ã€‚
        </div>
      </div>

      <div class="analogy">
        <h4>ğŸ¯ ç”Ÿæ´»é¡æ¯”ï¼šç ”ç©¶åŠ©ç†</h4>
        <p>æƒ³åƒä½ æœ‰ä¸€å€‹è¶…å¼·çš„ç ”ç©¶åŠ©ç†ï¼š</p>
        <ul>
          <li><strong>DPR æª¢ç´¢å™¨</strong> = åŠ©ç†å»åœ–æ›¸é¤¨æ‰¾ç›¸é—œæ›¸ç±</li>
          <li><strong>BART ç”Ÿæˆå™¨</strong> = åŠ©ç†é–±è®€é€™äº›æ›¸ï¼Œå¯«å‡ºå ±å‘Š</li>
        </ul>
        <p style="margin-top: 15px;">
          <strong>å‚³çµ± LLM</strong>ï¼šåŠ©ç†åªèƒ½é è¨˜æ†¶å›ç­”ï¼Œå¯èƒ½è¨˜éŒ¯<br />
          <strong>RAG</strong>ï¼šåŠ©ç†å…ˆæŸ¥è³‡æ–™å†å›ç­”ï¼Œç­”æ¡ˆæœ‰ä¾æ“š
        </p>
      </div>

      <!-- å…©ç¨® RAG è®Šé«” -->
      <h2>ğŸ”„ å…©ç¨® RAG è®Šé«”</h2>

      <div class="key-concept">
        <h4>RAG-Sequence vs RAG-Token</h4>
        <p>è«–æ–‡æå‡ºäº†å…©ç¨®ä¸åŒçš„æ•´åˆæ–¹å¼ï¼š</p>

        <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(280px, 1fr)); gap: 20px; margin-top: 20px;">
          <div style="background: var(--primary-light); padding: 20px; border-radius: var(--radius-md); border-left: 4px solid var(--primary-color);">
            <h5 style="color: var(--primary-color); margin-top: 0;">RAG-Sequence</h5>
            <p>æ¯å€‹æ–‡æª”ç”Ÿæˆä¸€å€‹å®Œæ•´ç­”æ¡ˆï¼Œæœ€å¾Œé¸æœ€å¥½çš„</p>
            <ul style="font-size: 0.9rem;">
              <li>æª¢ç´¢ k å€‹æ–‡æª”</li>
              <li>æ¯å€‹æ–‡æª”ç”Ÿæˆä¸€å€‹ç­”æ¡ˆ</li>
              <li>å°æ‰€æœ‰ç­”æ¡ˆåŠ æ¬Šå¹³å‡</li>
            </ul>
            <p style="font-size: 0.85rem; color: var(--text-secondary); margin-top: 10px;">
              é©åˆï¼šç­”æ¡ˆè¼ƒçŸ­ã€éœ€è¦ç²¾ç¢ºçš„ä»»å‹™
            </p>
          </div>

          <div style="background: var(--secondary-light); padding: 20px; border-radius: var(--radius-md); border-left: 4px solid var(--secondary-color);">
            <h5 style="color: var(--secondary-color); margin-top: 0;">RAG-Token</h5>
            <p>æ¯ç”Ÿæˆä¸€å€‹ tokenï¼Œéƒ½è€ƒæ…®æ‰€æœ‰æ–‡æª”</p>
            <ul style="font-size: 0.9rem;">
              <li>æª¢ç´¢ k å€‹æ–‡æª”</li>
              <li>ç”Ÿæˆæ¯å€‹ token æ™‚åƒè€ƒæ‰€æœ‰æ–‡æª”</li>
              <li>å‹•æ…‹é¸æ“‡æœ€ç›¸é—œçš„è³‡è¨Š</li>
            </ul>
            <p style="font-size: 0.85rem; color: var(--text-secondary); margin-top: 10px;">
              é©åˆï¼šéœ€è¦æ•´åˆå¤šä¾†æºè³‡è¨Šçš„ä»»å‹™
            </p>
          </div>
        </div>
      </div>

      <!-- æ•¸å­¸åŸç† -->
      <h2>ğŸ“ æ ¸å¿ƒæ•¸å­¸åŸç†</h2>

      <div class="original-quote">
        <strong>ğŸ“„ è«–æ–‡åŸæ–‡ï¼ˆæ•¸å­¸å…¬å¼ï¼‰</strong><br><br>
        "For RAG-Sequence, we marginalize over all retrieved documents to compute the probability of generating the sequence y: P(y|x) = Î£<sub>zâˆˆtop-k(D)</sub> P(z|x) Ã— P(y|x, z), where P(z|x) is the probability of retrieving document z given query x, and P(y|x, z) is the probability of generating y given x and z."
        <br><br>
        <strong>ç¿»è­¯</strong>ï¼šå°æ–¼ RAG-Sequenceï¼Œæˆ‘å€‘å°æ‰€æœ‰æª¢ç´¢åˆ°çš„æ–‡æª”é€²è¡Œé‚Šç·£åŒ–ï¼Œä»¥è¨ˆç®—ç”Ÿæˆåºåˆ— y çš„æ©Ÿç‡ï¼šP(y|x) = Î£<sub>zâˆˆtop-k(D)</sub> P(z|x) Ã— P(y|x, z)ï¼Œå…¶ä¸­ P(z|x) æ˜¯çµ¦å®šæŸ¥è©¢ x æª¢ç´¢æ–‡æª” z çš„æ©Ÿç‡ï¼ŒP(y|x, z) æ˜¯çµ¦å®š x å’Œ z ç”Ÿæˆ y çš„æ©Ÿç‡ã€‚
      </div>

      <div class="explanation">
        <h4>ğŸ”¢ å…¬å¼è§£æ</h4>
        <p>RAG çš„æ ¸å¿ƒæƒ³æ³•ç”¨æ•¸å­¸è¡¨ç¤ºï¼š</p>
        
        <div style="background: white; padding: 20px; border-radius: var(--radius-md); margin: 15px 0; font-family: monospace; text-align: center; font-size: 1.1rem;">
          P(y|x) = Î£<sub>zâˆˆtop-k(D)</sub> P(z|x) Ã— P(y|x,z)
        </div>
        
        <p>å…¶ä¸­ï¼š</p>
        <ul>
          <li><strong>x</strong> = è¼¸å…¥æŸ¥è©¢</li>
          <li><strong>y</strong> = ç”Ÿæˆçš„ç­”æ¡ˆ</li>
          <li><strong>z</strong> = æª¢ç´¢åˆ°çš„æ–‡æª”ï¼ˆå¾ top-k æ–‡æª”é›†åˆä¸­ï¼‰</li>
          <li><strong>P(z|x)</strong> = æ–‡æª”çš„ç›¸é—œæ€§æ©Ÿç‡ï¼ˆRetriever è¨ˆç®—ï¼‰</li>
          <li><strong>P(y|x,z)</strong> = çµ¦å®šæ–‡æª”å¾Œç”Ÿæˆç­”æ¡ˆçš„æ©Ÿç‡ï¼ˆGenerator è¨ˆç®—ï¼‰</li>
        </ul>

        <p style="margin-top: 20px; color: var(--text-secondary);">
          <strong>ç™½è©±ç¿»è­¯ï¼š</strong>ç”Ÿæˆç­”æ¡ˆçš„æ©Ÿç‡ = åŠ ç¸½æ‰€æœ‰å¯èƒ½æ–‡æª”çš„è²¢ç»ã€‚
          æ–‡æª”è¶Šç›¸é—œï¼ˆP(z|x) è¶Šé«˜ï¼‰ï¼Œå°ç­”æ¡ˆçš„å½±éŸ¿è¶Šå¤§ã€‚
        </p>
      </div>

      <!-- è¨“ç·´æµç¨‹ -->
      <h2>ğŸ“ è¨“ç·´æµç¨‹</h2>

      <div class="section-block">
        <h3>ç«¯åˆ°ç«¯è¨“ç·´</h3>
        <p>RAG çš„ä¸€å¤§å‰µæ–°æ˜¯å¯ä»¥ç«¯åˆ°ç«¯è¨“ç·´ï¼Œè®“æª¢ç´¢å™¨å’Œç”Ÿæˆå™¨ä¸€èµ·å„ªåŒ–ï¼š</p>
        
        <ol style="line-height: 2;">
          <li><strong>è¼¸å…¥æŸ¥è©¢ x</strong></li>
          <li><strong>DPR æª¢ç´¢</strong>ï¼šæ‰¾åˆ° top-k ç›¸é—œæ–‡æª” zâ‚, zâ‚‚, ..., zâ‚–</li>
          <li><strong>è¨ˆç®—ç›¸é—œæ€§</strong>ï¼šP(záµ¢|x) = softmax(æŸ¥è©¢å‘é‡ Â· æ–‡æª”å‘é‡)</li>
          <li><strong>BART ç”Ÿæˆ</strong>ï¼šå°æ¯å€‹æ–‡æª”ç”Ÿæˆç­”æ¡ˆæ©Ÿç‡ P(y|x, záµ¢)</li>
          <li><strong>é‚Šç·£åŒ–</strong>ï¼šP(y|x) = Î£ P(záµ¢|x) Ã— P(y|x, záµ¢)</li>
          <li><strong>è¨ˆç®—æå¤±</strong>ï¼šæœ€å¤§åŒ–æ­£ç¢ºç­”æ¡ˆçš„æ©Ÿç‡</li>
          <li><strong>åå‘å‚³æ’­</strong>ï¼šæ›´æ–° Retriever å’Œ Generator çš„åƒæ•¸</li>
        </ol>
      </div>

      <!-- å¯¦é©—çµæœ -->
      <h2>ğŸ“Š Results (å¯¦é©—çµæœ)</h2>

      <div class="original-quote">
        <strong>ğŸ“„ è«–æ–‡åŸæ–‡ï¼ˆä¸»è¦çµæœï¼‰</strong><br><br>
        "We fine-tune and evaluate our models on a wide range of knowledge-intensive NLP tasks and set the state-of-the-art on three open domain QA tasks, outperforming parametric seq2seq models and task-specific retrieve-and-extract architectures. For language generation tasks, we find that RAG models generate more specific, diverse and factual language than a state-of-the-art parametric-only seq2seq baseline."
        <br><br>
        <strong>ç¿»è­¯</strong>ï¼šæˆ‘å€‘åœ¨å¤šç¨®çŸ¥è­˜å¯†é›†å‹ NLP ä»»å‹™ä¸Šå°æ¨¡å‹é€²è¡Œå¾®èª¿å’Œè©•ä¼°ï¼Œä¸¦åœ¨ä¸‰å€‹é–‹æ”¾åŸŸå•ç­”ä»»å‹™ä¸Šé”åˆ°æœ€å…ˆé€²çš„çµæœï¼Œè¶…è¶Šäº†åƒæ•¸åŒ– seq2seq æ¨¡å‹å’Œç‰¹å®šä»»å‹™çš„æª¢ç´¢-æŠ½å–æ¶æ§‹ã€‚å°æ–¼èªè¨€ç”Ÿæˆä»»å‹™ï¼Œæˆ‘å€‘ç™¼ç¾ RAG æ¨¡å‹ç”Ÿæˆçš„æ–‡æœ¬æ¯”æœ€å…ˆé€²çš„ç´”åƒæ•¸åŒ– seq2seq åŸºç·šæ›´å…·é«”ã€æ›´å¤šæ¨£ä¸”æ›´ç¬¦åˆäº‹å¯¦ã€‚
      </div>

      <div class="solution">
        <h4>âœ… åœ¨çŸ¥è­˜å¯†é›†å‹ä»»å‹™ä¸Šçš„è¡¨ç¾</h4>
        
        <h5 style="margin-top: 20px;">Open-Domain QA</h5>
        <table>
          <thead>
            <tr>
              <th>è³‡æ–™é›†</th>
              <th>æ¨¡å‹</th>
              <th>Exact Match</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>Natural Questions</td>
              <td>RAG</td>
              <td style="font-weight: bold; color: var(--secondary-color);">44.5%</td>
            </tr>
            <tr>
              <td>TriviaQA</td>
              <td>RAG</td>
              <td style="font-weight: bold; color: var(--secondary-color);">56.1%</td>
            </tr>
            <tr>
              <td>WebQuestions</td>
              <td>RAG</td>
              <td style="font-weight: bold; color: var(--secondary-color);">45.2%</td>
            </tr>
          </tbody>
        </table>

        <h5 style="margin-top: 25px;">å…¶ä»–ä»»å‹™</h5>
        <ul>
          <li><strong>Jeopardy å•ç­”</strong>ï¼šç”Ÿæˆé¢¨æ ¼çš„ç­”æ¡ˆ</li>
          <li><strong>FEVER äº‹å¯¦é©—è­‰</strong>ï¼šåˆ¤æ–·é™³è¿°çœŸå‡</li>
          <li><strong>MS-MARCO</strong>ï¼šé–‹æ”¾å¼å•ç­”</li>
        </ul>
        
        <p style="margin-top: 15px; color: var(--text-secondary);">
          RAG åœ¨æ‰€æœ‰ä»»å‹™ä¸Šéƒ½è¶…è¶Šäº†ç´”åƒæ•¸åŒ–çš„æ¨¡å‹ï¼ˆå¦‚ BARTã€T5ï¼‰ï¼Œ
          è­‰æ˜ã€Œæª¢ç´¢å¢å¼·ã€å°çŸ¥è­˜å¯†é›†å‹ä»»å‹™éå¸¸æœ‰æ•ˆã€‚
        </p>
      </div>

      <!-- æ¶ˆèå¯¦é©— -->
      <h2>ğŸ”¬ é—œéµç™¼ç¾</h2>

      <div class="key-concept">
        <h4>ğŸ“ˆ æ¶ˆèå¯¦é©—çµè«–</h4>
        <ul>
          <li>
            <strong>æª¢ç´¢æ•¸é‡ kï¼š</strong>k=5 åˆ° k=10 æ•ˆæœæœ€å¥½ï¼Œå¤ªå¤šåè€Œæœƒå¼•å…¥å™ªéŸ³
          </li>
          <li>
            <strong>RAG-Sequence vs RAG-Tokenï¼š</strong>ä¸åŒä»»å‹™å„æœ‰å„ªå‹¢
          </li>
          <li>
            <strong>ç«¯åˆ°ç«¯è¨“ç·´ï¼š</strong>æ¯”åˆ†é–‹è¨“ç·´æ•ˆæœæ›´å¥½
          </li>
          <li>
            <strong>æ–‡æª”å“è³ªï¼š</strong>æª¢ç´¢å™¨çš„å“è³ªç›´æ¥å½±éŸ¿æœ€çµ‚æ•ˆæœ
          </li>
        </ul>
      </div>

      <!-- å¯¦ä½œæç¤º -->
      <h2>ğŸ’» å¯¦ä½œæç¤º</h2>

      <div class="section-block">
        <h3>ä½¿ç”¨ Hugging Face å¯¦ä½œ</h3>
        <p>RAG å·²æ•´åˆåˆ° Hugging Face Transformersï¼š</p>
        
        <pre style="background: #1e1e1e; color: #d4d4d4; padding: 20px; border-radius: var(--radius-md); overflow-x: auto; font-size: 0.9rem;">
<span style="color: #6a9955;"># è¼‰å…¥ RAG æ¨¡å‹</span>
<span style="color: #c586c0;">from</span> transformers <span style="color: #c586c0;">import</span> RagTokenizer, RagRetriever, RagSequenceForGeneration

<span style="color: #6a9955;"># åˆå§‹åŒ–</span>
tokenizer = RagTokenizer.from_pretrained(<span style="color: #ce9178;">"facebook/rag-sequence-nq"</span>)
retriever = RagRetriever.from_pretrained(<span style="color: #ce9178;">"facebook/rag-sequence-nq"</span>)
model = RagSequenceForGeneration.from_pretrained(<span style="color: #ce9178;">"facebook/rag-sequence-nq"</span>)

<span style="color: #6a9955;"># ä½¿ç”¨</span>
input_ids = tokenizer(<span style="color: #ce9178;">"What is the capital of France?"</span>, return_tensors=<span style="color: #ce9178;">"pt"</span>).input_ids
generated = model.generate(input_ids)
<span style="color: #dcdcaa;">print</span>(tokenizer.decode(generated[<span style="color: #b5cea8;">0</span>], skip_special_tokens=<span style="color: #569cd6;">True</span>))</pre>
      </div>

      <!-- èˆ‡å…¶ä»–å·¥ä½œçš„é—œä¿‚ -->
      <h2>ğŸ”— èˆ‡å…¶ä»–è«–æ–‡çš„é—œä¿‚</h2>

      <div class="explanation">
        <h4>RAG çš„ä¸Šä¸‹æ¸¸</h4>
        
        <p><strong>ä¸Šæ¸¸ï¼ˆå½±éŸ¿ RAG çš„å·¥ä½œï¼‰ï¼š</strong></p>
        <ul>
          <li><strong>REALM (2020.02)</strong>ï¼šè­‰æ˜æª¢ç´¢å¯ä»¥æ•´åˆé€²é è¨“ç·´</li>
          <li><strong>DPR (2020.04)</strong>ï¼šæä¾›é«˜å“è³ªçš„å¯†é›†æª¢ç´¢å™¨</li>
          <li><strong>BART (2019)</strong>ï¼šæä¾›å¼·å¤§çš„ Seq2Seq ç”Ÿæˆå™¨</li>
        </ul>

        <p style="margin-top: 20px;"><strong>ä¸‹æ¸¸ï¼ˆè¢« RAG å½±éŸ¿çš„å·¥ä½œï¼‰ï¼š</strong></p>
        <ul>
          <li><strong>RETRO (2021)</strong>ï¼šæ“´å±•åˆ°æ›´å¤§è¦æ¨¡çš„æª¢ç´¢</li>
          <li><strong>Self-RAG (2023)</strong>ï¼šåŠ å…¥è‡ªæˆ‘åæ€æ©Ÿåˆ¶</li>
          <li><strong>GraphRAG (2024)</strong>ï¼šæ•´åˆçŸ¥è­˜åœ–è­œ</li>
          <li><strong>æ‰€æœ‰ç¾ä»£ RAG ç³»çµ±</strong>ï¼šLangChainã€LlamaIndex ç­‰</li>
        </ul>
      </div>

      <!-- é™åˆ¶èˆ‡æŒ‘æˆ° -->
      <h2>âš ï¸ é™åˆ¶èˆ‡æŒ‘æˆ°</h2>

      <div class="key-concept" style="background: linear-gradient(135deg, #fff5f5, #ffe5e5);">
        <h4 style="color: var(--danger-color);">è«–æ–‡çš„å±€é™æ€§</h4>
        <ul>
          <li><strong>æª¢ç´¢å“è³ªä¾è³´</strong>ï¼šå¦‚æœæª¢ç´¢åˆ°éŒ¯èª¤æ–‡æª”ï¼Œç­”æ¡ˆä¹ŸæœƒéŒ¯</li>
          <li><strong>å»¶é²å¢åŠ </strong>ï¼šéœ€è¦é¡å¤–çš„æª¢ç´¢æ­¥é©Ÿ</li>
          <li><strong>çŸ¥è­˜åº«é™åˆ¶</strong>ï¼šåªèƒ½å›ç­”çŸ¥è­˜åº«ä¸­æœ‰çš„å…§å®¹</li>
          <li><strong>å–®æ¬¡æª¢ç´¢</strong>ï¼šä¸æœƒè¿­ä»£æª¢ç´¢ï¼ˆå¾Œä¾†çš„ Self-RAG è§£æ±ºï¼‰</li>
        </ul>
        <p style="margin-top: 15px; color: var(--text-secondary);">
          é€™äº›é™åˆ¶æˆç‚ºå¾ŒçºŒç ”ç©¶çš„æ”¹é€²æ–¹å‘ï¼Œå‚¬ç”Ÿäº† Advanced RAG å’Œ Agentic RAGã€‚
        </p>
      </div>

      <!-- ç¸½çµ -->
      <h2>ğŸ“ ç¸½çµ</h2>

      <div class="solution">
        <h4>âœ… RAG è«–æ–‡çš„æ ¸å¿ƒè²¢ç»</h4>
        <ol>
          <li><strong>å®šç¾©æ¶æ§‹</strong>ï¼šRetriever + Generator çš„ç¶“å…¸çµ„åˆ</li>
          <li><strong>ç«¯åˆ°ç«¯è¨“ç·´</strong>ï¼šå…©å€‹çµ„ä»¶å¯ä»¥ä¸€èµ·å„ªåŒ–</li>
          <li><strong>å…©ç¨®è®Šé«”</strong>ï¼šRAG-Sequence å’Œ RAG-Token</li>
          <li><strong>å»£æ³›é©ç”¨</strong>ï¼šå¤šç¨®çŸ¥è­˜å¯†é›†å‹ä»»å‹™éƒ½æœ‰æ•ˆ</li>
          <li><strong>é–‹æºå¯¦ä½œ</strong>ï¼šHugging Face å³å¯ä½¿ç”¨</li>
        </ol>
        <p style="margin-top: 20px; font-weight: 600; color: var(--secondary-color);">
          é€™ç¯‡è«–æ–‡é–‹å‰µäº†ä¸€å€‹æ–°æ™‚ä»£ï¼Œè®“ã€Œè®“ AI å…ˆæŸ¥è³‡æ–™å†å›ç­”ã€æˆç‚ºå¯èƒ½ï¼
        </p>
      </div>

      <!-- å»¶ä¼¸é–±è®€ -->
      <div class="quick-links" style="margin-top: 40px;">
        <a href="01-realm.html" class="quick-link">â† ä¸Šä¸€ç¯‡ï¼šREALM</a>
        <a href="index.html" class="quick-link">å›åˆ° RAG ç¸½è¦½</a>
        <a href="03-retro.html" class="quick-link">ä¸‹ä¸€ç¯‡ï¼šRETRO â†’</a>
      </div>

      <div class="quick-links" style="margin-top: 15px;">
        <a href="https://arxiv.org/abs/2005.11401" class="quick-link" target="_blank">ğŸ“„ RAG è«–æ–‡ (arXiv)</a>
        <a href="https://huggingface.co/facebook/rag-sequence-nq" class="quick-link" target="_blank">ğŸ¤— Hugging Face æ¨¡å‹</a>
        <a href="https://github.com/huggingface/transformers/tree/main/examples/research_projects/rag" class="quick-link" target="_blank">ğŸ’» å®˜æ–¹ç¨‹å¼ç¢¼</a>
      </div>

      <!-- ä½œè€…è³‡è¨Š -->
      <div style="margin-top: 40px; padding: 25px; background: var(--bg-body); border-radius: var(--radius-md); border-left: 4px solid var(--secondary-color);">
        <h4 style="color: var(--secondary-color); margin-top: 0;">ğŸ‘¨â€ğŸ”¬ é—œæ–¼ç¬¬ä¸€ä½œè€…</h4>
        <p>
          <strong>Patrick Lewis</strong> æ˜¯ RAG è«–æ–‡çš„ç¬¬ä¸€ä½œè€…ï¼Œç•¶æ™‚ä»»è·æ–¼ Facebook AI Research (ç¾ Meta AI)ã€‚
          é€™ç¯‡è«–æ–‡æˆç‚ºä»–åšå£«è«–æ–‡çš„é‡è¦çµ„æˆéƒ¨åˆ†ï¼Œå¾Œä¾†ä»–ç²å¾—äº† Time é›œèªŒçš„ AI 100 äººç‰©å ±å°ã€‚
          RAG é€™å€‹åç¨±å’Œæ¶æ§‹ï¼Œå·²ç¶“æˆç‚ºæ•´å€‹ç”¢æ¥­çš„æ¨™æº–ç”¨èªã€‚
        </p>
      </div>
    </div>
  </body>
</html>
