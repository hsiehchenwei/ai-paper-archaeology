<!DOCTYPE html>
<html lang="zh-TW">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Vision Transformer: 圖片就是 16x16 個詞彙 - AI Paper Archaeology</title>
    <meta name="description" content="深入解析 Vision Transformer (ViT)，理解如何將 Transformer 應用到視覺任務，開啟視覺 AI 的新紀元。">
    
    <!-- Fonts -->
    <link href="https://fonts.googleapis.com/css2?family=Noto+Serif+TC:wght@400;700&family=Inter:wght@400;600;700&display=swap" rel="stylesheet">
    
    <!-- Styles -->
    <link rel="stylesheet" href="../styles/global.css">
    <link rel="stylesheet" href="../styles/paper-reading.css">
    
    
</head>
<body>
    <!-- Glass Navigation -->
    <nav class="glass-nav">
        <a href="../index.html" class="nav-link">🏠 首頁</a>
        <div class="nav-divider"></div>
        <a href="../clip-tutorial/index.html" class="nav-link">← CLIP</a>
        <span class="nav-link" style="color: var(--mag-primary); font-weight: 700;">ViT</span>
        <a href="../instructgpt-tutorial/index.html" class="nav-link">InstructGPT →</a>
    </nav>

    <!-- Hero Section -->
    <header class="tutorial-hero">
        <div class="hero-content-wrapper">
            <span class="hero-tag">AI Paper Archaeology · 2020</span>
            <h1 class="hero-title">Vision Transformer</h1>
            <p class="hero-subtitle">An Image is Worth 16x16 Words · 開啟視覺 AI 的新紀元</p>
            <div style="display: flex; gap: 15px; justify-content: center;">
                <a href="01-introduction.html" class="button" style="background: white; color: black; border-radius: 99px; padding: 12px 32px; font-weight: 600; text-decoration: none;">開始閱讀</a>
                <a href="https://arxiv.org/abs/2010.11929" target="_blank" class="button" style="background: rgba(255,255,255,0.1); backdrop-filter: blur(10px); color: white; border: 1px solid rgba(255,255,255,0.3); border-radius: 99px; padding: 12px 24px; font-weight: 500; text-decoration: none;">原始論文 ↗</a>
            </div>
        </div>
    </header>

    <!-- Learning Path Section -->
    <section>
        <div class="section-header">
            <h2 class="section-title">學習路徑指引</h2>
            <p style="color: var(--text-secondary);">如何循序漸進掌握這篇開創性論文</p>
        </div>
        <div class="learning-path-grid">
            <div class="path-step">
                <div class="step-icon">🎯</div>
                <h3 style="margin-bottom: 10px;">核心概念</h3>
                <p style="font-size: 0.9rem; color: var(--text-secondary);">從 <a href="01-introduction.html">第 1 章</a> 理解為何要把 Transformer 應用到視覺，以及 ViT 的突破性貢獻。</p>
            </div>
            <div class="path-step">
                <div class="step-icon">🔪</div>
                <h3 style="margin-bottom: 10px;">Patch Embedding</h3>
                <p style="font-size: 0.9rem; color: var(--text-secondary);">在 <a href="02-patch-embedding.html">第 2 章</a> 深入理解如何把圖片切成 16x16 的碎片，轉換成 tokens。</p>
            </div>
            <div class="path-step">
                <div class="step-icon">🏗️</div>
                <h3 style="margin-bottom: 10px;">模型架構</h3>
                <p style="font-size: 0.9rem; color: var(--text-secondary);">探索 <a href="03-architecture.html">第 3 章</a> 的 Transformer Encoder 結構與歸納偏置對比。</p>
            </div>
            <div class="path-step">
                <div class="step-icon">📊</div>
                <h3 style="margin-bottom: 10px;">實驗結果</h3>
                <p style="font-size: 0.9rem; color: var(--text-secondary);">在 <a href="04-experiments.html">第 4 章</a> 體驗 ViT 如何超越 SOTA，用更少的計算資源達到更好的性能。</p>
            </div>
        </div>
    </section>

    <!-- Chapters Grid -->
    <section>
        <div class="section-header">
            <h2 class="section-title">章節導覽</h2>
        </div>
        
        <div class="chapters-grid">
            <!-- Chapter 1 -->
            <a href="01-introduction.html" class="chapter-card">
                <div class="card-number">CHAPTER 01</div>
                <h3 class="card-title">引言與動機</h3>
                <p class="card-desc">理解為何 Transformer 在 NLP 成功，在視覺卻落後？探索 ViT 如何用「大規模訓練勝過歸納偏置」的核心理念改變視覺 AI。</p>
                <div class="card-meta">
                    <div class="read-time">
                        <span>⏱️</span> 25 min read
                    </div>
                    <div class="card-arrow">→</div>
                </div>
            </a>

            <!-- Chapter 2 -->
            <a href="02-patch-embedding.html" class="chapter-card">
                <div class="card-number">CHAPTER 02</div>
                <h3 class="card-title">Patch Embedding</h3>
                <p class="card-desc">深入理解如何把圖片切成 16x16 的碎片，轉換成向量，加上位置編碼，最終變成 Transformer 可以處理的序列。</p>
                <div class="card-meta">
                    <div class="read-time">
                        <span>⏱️</span> 20 min read
                    </div>
                    <div class="card-arrow">→</div>
                </div>
            </a>

            <!-- Chapter 3 -->
            <a href="03-architecture.html" class="chapter-card">
                <div class="card-number">CHAPTER 03</div>
                <h3 class="card-title">模型架構全解析</h3>
                <p class="card-desc">探索 ViT 的 Transformer Encoder 結構、歸納偏置對比（CNN vs ViT）、模型變體（Base/Large/Huge），以及 Fine-tuning 策略。</p>
                <div class="card-meta">
                    <div class="read-time">
                        <span>⏱️</span> 30 min read
                    </div>
                    <div class="card-arrow">→</div>
                </div>
            </a>

            <!-- Chapter 4 -->
            <a href="04-experiments.html" class="chapter-card">
                <div class="card-number">CHAPTER 04</div>
                <h3 class="card-title">實驗結果與 SOTA 對比</h3>
                <p class="card-desc">深入分析 ViT 在多個基準測試上的表現，與 BiT、Noisy Student 的對比，以及計算效率的優勢。</p>
                <div class="card-meta">
                    <div class="read-time">
                        <span>⏱️</span> 25 min read
                    </div>
                    <div class="card-arrow">→</div>
                </div>
            </a>

            <!-- Chapter 5 -->
            <a href="05-scaling-and-data.html" class="chapter-card">
                <div class="card-number">CHAPTER 05</div>
                <h3 class="card-title">資料規模與泛化能力</h3>
                <p class="card-desc">理解為什麼 ViT 需要大規模資料，探索 Attention 距離分析、位置編碼的學習，以及泛化能力的來源。</p>
                <div class="card-meta">
                    <div class="read-time">
                        <span>⏱️</span> 30 min read
                    </div>
                    <div class="card-arrow">→</div>
                </div>
            </a>

            <!-- Chapter 6 -->
            <a href="06-conclusion.html" class="chapter-card">
                <div class="card-number">CHAPTER 06</div>
                <h3 class="card-title">結論與影響</h3>
                <p class="card-desc">總結 ViT 的歷史意義、後續發展（DeiT、Swin、CLIP），以及對 AI 研究的啟示：擴展優先、統一架構、計算效率。</p>
                <div class="card-meta">
                    <div class="read-time">
                        <span>⏱️</span> 25 min read
                    </div>
                    <div class="card-arrow">→</div>
                </div>
            </a>
        </div>
    </section>

    <!-- Footer -->
    <footer style="text-align: center; padding: 60px 20px; color: var(--text-secondary); border-top: 1px solid #e5e7eb;">
        <p>© 2026 AI Paper Archaeology</p>
        <p style="font-size: 0.9rem; margin-top: 10px;">Made with ❤️ for AI Learners</p>
    </footer>

</body>
</html>
